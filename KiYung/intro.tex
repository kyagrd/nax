\chapter{Introduction}\label{ch:intro}

\section{Programming and Formal Reasoning}\label{sec:intro:motiv}
In this dissertation, we contribute to answering the question:
``how does one build a seamless system where programmers can both
write (functional) programs and formally reason about those programs''.
In late 1960s, \citet{Howard69} observed that natural deduction, which is
a proof system of a formal logic, and a typed lambda calculus, which is
a model of computation, are directly related --
a proof of a proposition corresponds to a program and its type.
Since this observation, known as the Curry--Howard correspondence,
logicians and programming language researchers 
have  dreamed of
building a system in which one can both write programs
(\ie, model computation) and formally reason about (\ie, construct proofs of)
the properties (\ie, types) of those programs.

However, building a practical system that unifies programming and
formal reasoning, based on the Curry--Howard correspondence, is still
an open research problem. The gap between the conflicting
design goals of typed functional programming languages, such as ML and Haskell,
and formal reasoning systems, such as Coq and Agda, is still wide.

Programming languages are typically designed to achieve
computational expressiveness. They often sacrifice logical consistency
to achieve this goal. Programmers should be able to
conveniently express all possible computations, regardless of whether those
computations have a logical interpretation or not.

Formal reasoning systems are typically designed to achieve logical consistency.
They often sacrifice computational expressiveness to achieve that goal.
Users expect that it is only possible to prove true propositions,
and it is impossible to prove falsity. They are willing
live with the difficultly (or even impossibility) to
express certain computations within the reasoning system,
to achieve logical consistency.

As a result, the recursion schemes of programming languages and
formal reasoning systems differ considerably.
Programming languages provide unrestricted general recursion,
to conveniently express computations
that may or may not terminate.
Formal reasoning systems provide induction principles for sound reasoning,
or, in the computational view, principled recursion schemes
that can only express terminating computation.

The two different design goals also lead to significant differences
in their type system as well.
Programming languages are based on the \emph{recursive types} paradigm,
which accepts as much type definition as possible written by the type syntax
so that programmers can express computations over a wide variety types.
In addition, most (statically typed) functional programing languages have
clear distinction between terms and types (\ie, terms do not appear in types).
Reasoning systems are usually based on the \emph{inductive types} paradigm,
which only accepts type definitions that are amenable to
conventional induction principles but rejects all the other definitions.
In addition, most reasoning systems based on Curry--Howard correspondence
allow types to depend on terms (\ie, terms can appear in types) to specify
fine grained properties.

This dissertation explores a sweet spot where one can benefit from
the advantages of both programming languages and formal reasoning systems.
That is, we design a unified language system, called Nax, which is
logically consistent while being able to conveniently express
many useful computations. We do this by allowing as much type definition
as possible, as in programming languages, but provide a rich set of
non-conventional recursion schemes (or, induction principles) that
always terminate. These non-conventional recursion schemes are known as
\emph{the Mendler style}. There are several other design choices we made
in Nax that sits in the middle of the typical features of programming languages
and reasoning systems, such as \emph{indexed types}, which allow only
erasable terms to appear in types.

\section{Thesis}\label{sec:intro:thesis}

\begin{enumerate}[(1)]
 \item Nax supports the major constructs of modern
         functional programming languages, such as
         parametric polymorphism, recursive datatypes, and type inference,
 \item Nax can specify fine-grained program properties as types and
         witness proofs of such properties by writing a program
         (The Curry--Howard correspondence),
 \item Nax is based on a minimal foundational calculus
 that is expressive enough to embed all language constructs in (1)
 and is also logically consistent to avoid paradoxical proofs in (2),
 \item Nax has a simple implementation infrastructure
         that keeps the trusted base small.
\end{enumerate}


TODO write a thesis section

the Curry--Howard correspondence
Mendler-style recursion schemes and term-indexed types

Mix things below

\begin{quote}
A language equipped with \emph{term indexed types} and
\emph{Mendler-style recursion combinators} can be 
(1) a basis for \emph{sound and consistent logic}
suitable for reasoning about properties of (functional) programs
and also
(2) a basis for a \emph{simple and expressive programming language}
suitable for writing the (functional) programs to be reasoned about.
\end{quote}



\section{Preliminary concepts}\label{sec:intro:concepts}
TODO section leading paragraph

\subsection{The Curry--Howard correspondence and Normalization}
\label{sec:intro:concepts:CH}
One promising approach to designing a system that unifies
logical reasoning and programming is \emph{the Curry--Howard correspondence}.
Howard \cite{Howard69} observed that a typed model of computation
(\ie, a typed lambda calculus) gives an interpretation to a (natural deduction)
proof system (for an intuitionistic logic). More specifically, one can interpret
a type (in the lambda calculus) as a formula (in the logic) and
a term of that type, as a proof for that formula. For instance,
the typing rule for function applications (APP) in a typed lambda calculus
corresponds to Modus Ponens (MP) in a logic:
\[ \inference[(APP)]{\Gamma |- t_1 : A -> B & \Gamma |- t_2 : A}{
        \Gamma |- t_1~t_2 : B}
 ~~~~~~~~
   \inference[(MP)]{A -> B & A}{B}
\]
As you can see above, combining terms ($t_1$ and $t_2$) to build a new term
($t_1~t_2$) can be interpreted as combining proofs for formulae
($A -> B$ and $A$), to construct a proof for a new formula ($B$).
More generally, we may expect that programming (\ie, building larger terms)
corresponds to constructing larger proofs only when the typed lambda calculi
meets certain standards -- \emph{type soundness} and \emph{normalization}.

The Curry--Howard correspondence is a promising approach to designing a
unified system for both logical reasoning and programming. Only one language
system is needed for both the logic and the programming language. An
alternate approach is to use an external logical language to talk about
programs as the objects that the logic reasons about. In this approach, one
has the obligation to argue that the soundness of the logic, with respect to
the programming language semantics, holds.

Under the Curry--Howard correspondence, the logic is internally related to the
semantics of program -- there is no need to argue for the soundness of the
logic,  externally outside of the programming language system. The soundness
of the logic follows directly from the type soundness of the language under
the Curry--Howard correspondence.

Let us consider a proposition to be true
(or, valid) when it has a canonical (\ie, cut-free) proof.
That is, there is a program, whose type is the proposition under
consideration, and that program has a normal form. 
By type soundness, any term,
of that type, will preserve its type during the reduction steps. Thus
reduction preserves truthfulness. If we assume
that the language is normalizing (\ie, every well-typed term reduces to
a normal form), then any term of that type which is a non-canonical proof,
implies the existence of a canonical proof, which in turn implies that
the proposition specified by the type is indeed true. That is, all provable
propositions are valid (\ie, the logic is sound) when the language is
\emph{type sound} and \emph{normalizing}.

\emph{Normalization} is also essential for the consistency of the logic.
For the lambda calculus to be interpreted as a \emph{consistent} logic,
there must be no diverging terms. A diverging term (\ie, a term that does
not have a normal form) may inhabit any arbitrary type. Thus, a diverging term
can be a proof for any proposition under the Curry--Howard correspondence.
General purpose functional programming languages (\eg, Haskell and ML), that
support unrestricted general recursion, cannot be interpreted as a consistent
logic, since they allow diverging terms (non-terminating programs).
For example, a diverging Haskell definition $\textit{loop} = \textit{loop}$
can be given an arbitrary type such as
$\textit{loop}\mathrel{::}\textit{Bool}$,
$\textit{loop}\mathrel{::}\textit{Int} -> \textit{Bool}$,
and even $\textit{loop}\mathrel{::}\forall a. a$, which is a proof of false.


Therefore, useful logical reasoning systems based on the Curry--Howard
correspondence (\eg, Coq, Agda) never support language features that can
lead to diverging terms. For example, in both Coq and Agda,
unrestricted general recursion (at term level) is not supported. 
Instead, these logical reasoning systems
often provide principled recursion schemes over recursive types that are
guaranteed to normalize. 

Recursive types (\ie, recursion at type level)
can also lead to diverging terms when they are not restricted carefully.
Many of the conventional logical reasoning systems, based on
Curry--Howard correspondence, restrict recursive types in a way,
which is not an ideal design choice, if one's goal is a unified system for
logic and programming. My approach explores another design space not yet
completely explored. We introduce both approaches to restricting recursive
types to ensure normalization in the following two subsections.


\subsection{Restriction on recursive types for normalization}
\label{sec:intro:concpets:recursive}
We have argued that normalization is essential for logical reasoning systems
based on the Curry--Howard correspondence. One challenge to the successful
design of such systems is how to restrict recursion at the type level
so that normalization of terms is preserved. 
There are two different
design choices illustrated in Figure~\ref{fig:approaches}. 
The conventional approach restricts the formation
of recursive types (\ie, the restriction is in datatype definition), and
the Mendler-style approach restricts the elimination
of the values of recursive types (\ie, the restriction is in pattern matching).

\begin{figure}
{\centering
\begin{tabular}{p{3cm}|p{12.5cm}}
\parbox{3cm}{~~Functional\\programming\\$~~~~$language} &
\parbox{12.5cm}{
 kinding:~
  \inference[($\mu$-form)]{\Gamma |- F : * -> *}{\Gamma |- \mu F : *} \\
 \\
 typing:\quad
  \inference[($\mu$-intro)]{\Gamma |- t : F (\mu F)}{\Gamma |- \In~t:\mu F} ~~~~
  \inference[($\mu$-elim)]{\Gamma |- t : \mu F}{\Gamma |- \unIn~t : F (\mu F)}\\
 \\
 reduction:
  \inference[(\unIn-\In)]{}{\unIn~(\In~t) \rightsquigarrow t}
} \\
\\ \hline\hline
\parbox{3cm}{$~$Conventional\\$~~~$approach for\\consistent logic} &
\parbox{12.5cm}{$\phantom{a}$\\
 kinding:~
  \inference[($\mu$-form$^{+}$)]{ \Gamma |- F : * -> * 
                           & \mathop{\mathsf{positive}}(F)}
                           {\Gamma |- \mu F : *} \\
 \\
 typing:~
  \text{{\small($\mu$-intro)} and {\small($\mu$-elim)}
                same as functional language} \\
  \[\inference[(\It)]{\Gamma |- t : \mu F & \Gamma |- \varphi : F A -> A}
                     {\Gamma |- \It~\varphi~t : A}\]
 reduction:~ \text{{\small(\unIn-\In)} same as functional language}
  \[\inference[(\It-\In)]{}{\It~\varphi~(\In~t) \rightsquigarrow
                            \varphi~(\textsf{map}_F~(\It~\varphi)~t)}\]
}
\\ \hline
\parbox{3cm}{Mendler-style\\$~~$approach for\\consistent logic} &
\parbox{12.5cm}{$\phantom{a}$\\
 kinding:~ \text{{\small($\mu$-form)} same as functional language} \\
 \\
 typing:~
  \text{{\small($\mu$-intro)} same as functional language}
  \[\inference[(\MIt)]
     { \Gamma |- t : \mu F &
       \Gamma |- \varphi : \forall X . (X -> A) -> F X -> A}
     {\Gamma |- \MIt~\varphi~t : A} \]
 reduction:~
  \inference[(\MIt-\In)]
     {}
     {\MIt~\varphi~(\In~t) \rightsquigarrow \varphi~(\MIt~\varphi)~t}
}
\end{tabular} }
\caption{Two different approaches to designing a logic
         (in contrast to functional languages)}
\label{fig:approaches}
\end{figure}

\paragraph{Recursive types in functional programming languages.}
Let us start with a review of the theory of recursive types used
in functional programming languages. Here, the term
language is not expected to be normalizing, so restrictions are few.

Just as we can capture the essence of unrestricted general recursion at term
level, by a fix point operator (usually denoted by \textsf{Y} or \textsf{fix}),
we can capture the essence of recursive types by the
use of fix point operator, $\mu$, at type level. 
The rules for the formation {\small($\mu$-form)},
introduction {\small($\mu$-intro)}, and elimination {\small($\mu$-elim)} of
the recursive type operator $\mu$ are described in Figure \ref{fig:approaches}.
We also need a reduction rule {\small(\unIn-\In)}, which relates \In,
the data constructor for recursive types, and \unIn, the destructor for
recursive types, at the term level.

Surprisingly (if you hadn't known), the recursive {\em type} operator, $\mu$,
as described in Figure \ref{fig:approaches}, is already powerful enough to
express non-terminating programs, even without introducing the general recursive
{\em term} operator, \textsf{fix}, to the language. We illustrate this below.
First a short reminder of how a fixpoint at the term level operates.
The typing rule and the reduction rule for \textsf{fix} can be given as follows:
\[ \text{typing:}~ \inference{\Gamma |- f : A -> A}{\textsf{fix}\,f : A}
 \qquad\qquad
   \text{reduction}:~ \textsf{fix}\,f \rightsquigarrow f(\textsf{fix}\,f)
\]
We can actually implement \textsf{fix}, using $\mu$, as follows
(using some Haskell-like syntax):
\begin{align*}
& \textbf{data}~T\;a\;r = C\;(r -> a) \quad
          \texttt{-}\texttt{-}~\text{\small a non-recursive datatype} \\
& w \,:\, \mu(T\;a) -> a ~~ \quad
          \texttt{-}\texttt{-}~\text{\small an encoding of the untyped
                                     $(\lambda x.x\;x)$
                                     in a typed language}~ \\
& w = \lambda x . \,\textbf{case}~\unIn~x~\textbf{of}~C\;f -> f\;x \\
& \textsf{fix} \,:\, (a -> a) -> a \quad
          \texttt{-}\texttt{-}~\text{\small an encoding of 
                                     $(\lambda f.(\lambda x.f(x\;x))\,
                                                 (\lambda x.f(x\;x)))$} \\
& \textsf{fix} = \lambda f. (\lambda x. f (w\;x))\,(\In(C(\lambda x. f (w\;x))))
\end{align*}

Thus, to avoid the loss of termination guarantees, we need to alter the rules
for $\mu$, in someways, to ensure a consistent logic. One way, is to restrict
the rule {\small $\mu$-form}; the other way, is to restrict the rule
{\small $\mu$-elim}. Once we decide which of these two alterations of the
rules we will use, the design of principled recursion combinators (\eg, \It\
for the former and \MIt\ for the latter) follows from that choice.

\paragraph{Recursive types in the conventional approach to consistent logic.}
In the conventional approach, the formation (\ie, datatype definition) of
recursive types is restricted, but arbitrary elimination (\ie, pattern matching)
over the values of recursive types is allowed. In particular, the formation of
negative recursive types is restricted. Only positive recursive types are
supported. Thus, in Figure \ref{fig:approaches}, we have a restricted version of
the formation rule {\small($\mu$-form$^{+}$)} has an additional condition that
require $F$ to be positive. The other rules {\small($\mu$-intro)},
{\small($\mu$-elim)}, and {\small(\unIn-\In)} remain the same as for
functional languages. Since we have restricted the recursive types
at the type level and we do not have general recursion at the term level,
the language is indeed normalizing. However, we can neither write
interesting (\ie, recursive) programs that involves recursive types nor
inductively reason about those programs, unless we have principled recursion
schemes that are guaranteed to normalize. One such recursion scheme is called
iteration (\aka\ catamorphism). The typing rules for the conventional iteration
\It\ are illustrated in Figure \ref{fig:approaches}. Note, we have the typing
rule {\small(\It)} and the reduction rule {\small(\It-\In)} for \It\,
in addition to the rules for the recursive type operator $\mu$.

\paragraph{Recursive types in the Mendler style approach to consistent logic.}
In the Mendler-style approach, we allow arbitrary formation
(\ie, datatype definition) of recursive types, but we restrict
the elimination (\ie, pattern matching) over the values of recursive types. 
The formation rule {\small($\mu$-form)} remains the same as
for functional languages. That is, we can define arbitrary recursive types,
both positive and negative. However, we no longer have the elimination
rule {\small($\mu$-elim)}. That is, we are not allowed to pattern match over
the values of recursive types in the normal fashion. We can only pattern match
over the values of recursive types through the Mendler-style recursion
combinators. The rules for the Mendler-style iteration combinator \MIt\
are illustrated in Figure \ref{fig:approaches}.
Note, there are no rules for \unIn\ in the Mendler-style approach.
The typing rule {\small($\mu$-elim)} is replaced by {\small(\MIt)} and
the reduction rule {\small(\unIn-\In)} is replaced by {\small(\MIt-\In)}.
More precisely, the typing rule {\small \MIt} is both an elimination rule
for recursive types and a typing rule for the Mendler-style iterator.
You can think of the rule {\small(\MIt)} as replacing both the elimination rule
{\small($\mu$-elim)} and the typing rule for conventional iteration
{\small(\It)}, but in a safe way that guarantees normalization.

\subsection{Justification of the Mendler-style as a design choice.}
\label{sec:intro:concepts:mendler}
We choose to base our approach to the design of a seamless synthesis of both
logic and programming on the Mendler-style. It restricts the elimination (\ie,
pattern matching) over values of recursive types, rather restricting the
formation (\ie, datatype definition) of recursive types (a more conventional
approach). The impact of this design choice is that it enables the logic to
include all datatype definitions that are used in functional programming
languages.

Functional programming promotes ``functions as first class values''.
It is natural to pass functions as arguments and embed functions into
(recursive) datatypes. If embedding functions in datatypes is allowed,
we can embed a function whose domain is the very type we are defining.
For example, the recursive datatype definition
$\mathbf{data}~T = C\;(T -> \textit{A})$ in Haskell is such a recursive
datatype definition. Such datatypes are called negative recursive datatypes
since the recursive occurrence $T$ appears in a negative position.
We say that $T$ is in a negative position, since $(T -> A)$ is analogous to
$(\neg T \land A)$ when we think of $->$ as a logical implication. There exist
both interesting and useful examples in functional programming involving
negative datatypes. In \S\ref{sec:msf}, we illustrate that
the Mendler-style recursion scheme, which we discovered, can express
interesting examples involving negative datatypes.

Recall that the motivation of this dissertation research
(quoting again from \S\ref{sec:intro:motiv})
is to contribute to answering the question of {\em how does one build a
seamless system where programmers can both write (functional) programs and
formally reason about those programs}. Under the Curry--Howard correspondence,
to formally reason about a program, the logic needs to refer to the type of
the program, since the type, interpreted as a proposition, describes its
properties. Since the Mendler-style approach does not restrict recursive
datatype definitions, we can directly refer to the types of programs that use
negative recursive types.

The Mendler style is a promising approach to building a unified system because
all the recursive types, both positive and negative, are definable in the
logic. Although the conventional approach is widely followed in the design of
formal reasoning systems based on the Curry--Howard correspondence (\eg, Coq,
Agda), it cannot directly refer to programs that use non-positive recursive
types. One may object that it is possible to indirectly model negative
recursive types in the conventional style, via alternative equivalent
encodings which map negative recursive types into positive ones. But, such
encodings do not align with our motivation towards a seamless unified
system for both programming and reasoning. It is undesirable to require
programmers to significantly change their programs just to reason about them.
If the change is unavoidable, it should kept small. That is,
the changed program syntactically resemble the original program,
which the programmer would usually write in functional programming languages.
In Chapter 3, we show a number of examples that the programs written in
the Mendler style look a lot alike the programs written in general recursion
than the programs written in the conventional style.

Another benefit of the Mendler style is that there exist recursion schemes
that are both useful and well-behaved (\ie, guaranteed to normalize) for
arbitrary recursive types. A Mendler-style recursion scheme is
an induction principle for logical reasoning as well as
a principled recursion scheme for describing computation (\ie, programming).
It would not be meaningful to have arbitrary recursive types
in the logic unless we have useful and well-behaved induction principles
to reason about the programs using those recursive types.
This is especially true for the negative recursive types.

The Mendler-style iteration, \MIt, is a well-behaved for both positive and
negative recursive types. For positive recursive types, \MIt\ is as expressive
as the conventional style iteration \It\ (\ie, both can be defined in terms of
each other). Furthermore, \MIt\ behaves well (\ie, always normalizes), even for
negative recursive types.

There exist other families of Mendler-style recursion combinators,
which are even more useful than \MIt\ for negative recursive types,
some of which we have discovered in during the thesis research. Throughout
this dissertation, we show that the Mendler-style recursion combinators are
indeed useful and well-behaved induction principles.

%% Further details on
%% Mendler-style recursive schemes are provided in Chapter \ref{ch:mendler}.

\subsection{Indexed types and type inference}
\label{sec:intro:indexed}
One of the most frequently asked questions on the design choices of Nax
is "why not dependent types?".

But more importantly, datatypes are not self-contained in
dependent type theories. That is, datatypes must be supported as
primitive constructs, rather than as encodings in pure lambda calculi,
in order to enjoy full ramifications recursive dependent datatypes.
%% For instance, in Calculus of Constructions (CC) [TODO cite CC],
%% induction principles are not deriviable
%% Church-encodings
%% Due to the [cite H. Geuvers 2001]

On the contrary, in polymorphic type theories, all imaginalbe datatypes can
have functional encodings (\eg, Church encodings). For instance, \Fw\ does not
need to introduce datatypes as primitive constructs, since it can embed all
imaginable datatypes within the thoery, including non-regular recursive
datatypes with type indices. 
TODO small theory

We do know know how to extend Mendler-style recursion schemes
that can express dependently typed recursive functions over
negative datatypes.
There exists ideas (although not published anywere yet)\footnote{
	Tarmo Uustalu wrote this on a whiteboard
	when I met him during my Cambridge visit on 2011.}
on Mendler-style recursion schemes over dependently-typed functions
over positive datatypes (\ie, datatypes that have map).

aaa
TODO some description of indexed types
why we are not going to dependent types

refer to Part \ref{part:Calculi}
TODO

a note on type inference
Hindely--Milner
bidirectional and other things

\section{Contributions}\label{sec:intro:contrib}
This dissertation makes contributions in several areas.
\begin{itemize}
\item[1.]
It organizes and expands the realm of \emph{Mendler-style recursion schemes}
(Part~\ref{part:Mendler}, \ie, Chapter \ref{ch:mendler})

\item[2.] It establishes a meta-theories for \emph{term-indexed types}
        (Part~\ref{part:Calculi}),

\item[3.] It designs a practical language (with an implementation)
        \emph{in the sweet spot} between programming and logical reasoning
        (Part~\ref{part:Nax}), and

\item[4.] It identifies several interesting open problems related to above.
\end{itemize}

\subsection{Contributions related to the Mendler style}
We organize a hierarchy of Mendler-style recursion schemes in two dimensions.
The first dimension is the abstract operations they support. For instance,
the Mendler-style iteration (\MIt) supports a single abstract operation
the recursive call. All the other Mendler-style recursion schemes
support the recursive call and an additional set of abstract operations. 
The second dimension is over the kind of the datatypes they operate over.
For example, \texttt{Nat} has kind $*$, while \texttt{Vec}
has kind $* -> \mathtt{Nat} -> *$. Each recursion scheme is actually a
family of recursion combinators sharing the same term definition
(\ie, uniformly defined) but with different type signatures at each kind.

We expand the realm of Mendler-style recursion schemes in several ways.
First, we report on a new recursion scheme $\MsfIt$, which is useful
for negative datatypes.  Second, we study the termination behaviors
of Mendler-style recursion schemes. Some recursion schemes (\eg, \MIt, \MsfIt)
always terminate for any recursive type, while others (\eg, \McvPr) only
terminate for certain classes of recursive types. Third, we extend
all Mendler-style recursion schemes to be expressive over term-indexed types.
The Mendler style has been studied in the context of \Fw\ (and several
extensions) which can express type-indexed types. To extend Mendler-style
recursion schemes to be expressive over term-indexed types, we report on
several theories for calculi (\Fi\ and \Fixi) that support term indices.
This is another important area of our contribution.

In addition, we develop a better understanding of some existing
Mendler-style recursion schemes. For instance, the existence of
Mendler-style course-of-values recursion (\McvPr) is reported
in the literature, but the calculus that can embed \McvPr\ was unknown.
We embed Mendler-style course-of-values recursion into \Fixi
(or into \Fixw, when we do not consider term-indices).

\subsection{Contributions to the theory of Term-Indexed Types}
Mendler-style recursion schemes have been studies in the context of
polymorphic lambda calculi. For instance, \citet{AbeMatUus03} embedded 
Mendler-style iteration (\MIt) into \Fw\ and \citet{AbeMat04} embedded
Mendler-style primitive recursion (\MPr) into \Fixw. These calculi
support type-indexed types.

To extend the realm of Mendler-style recursion schemes to include
term-indexed types, we extended \Fw\ and \Fixw\ to support term indices.
In Part \ref{part:Calculi}, we present our new calculi
\Fi\ (Chapter \ref{ch:fi}), which extends \Fw\ with term indices, and
\Fixi (Chapter \ref{ch:fixi}), which extends \Fixw\ with term indices.
These calculi have an erasure property that states that well-typed terms
in each calculus are also well typed terms (when erased) in the 
underlying calculus. For instance, any well typed term in \Fi\ is also
a well-typed term in \Fw, and there are no additional well-typed terms
in \Fi\ that are not well-typed in \Fw.

Our new calculi, \Fi\ and \Fixi, are strongly normalizing and
logically consistent. We show strong normalization and logical consistency
using the erasure properties. That is, strong normalization and
logical consistency of \Fi\ and \Fixi\ are inherited from \Fw\ and \Fixw.
Since \Fi\ and \Fixi\ are strong normalizing and logically  consistent,
the Mendler-style recursion schemes that can be embedded into these calculi
are adequate for logical reasoning as well as programming.

\subsection{Contributions in the design of the Nax language}
We design and implement a prototypical language Nax that explores
the sweet spot between programming oriented systems and logic oriented systems.
The language features supported by Nax provide the advantages
of both programming oriented systems and logic oriented systems.
Nax supports both term- and type-indexed datatypes,
rich families of Mendler-style recursion combinators,
and a conservative extension of Hindley--Milner type inference.
We designed Nax so that its foundational theory and
implementation framework could be kept simple.

Term- and type-indexed datatypes can express fine grained program properties
via the Curry--Howard correspondence, as in logic oriented systems. Although
not as flexible as full-fledged dependent types, indexed datatypes can
still express program invariants, such as type preserving compilation,
and size invariants on data structures. Index types can simulate much of what
dependent types can do using singleton types. Since Nax has only erasable
indices, the foundational theory can be kept simple, and it supports
features that have the advantages of programming oriented systems 
(\eg, type inference, arbitrary recursive datatypes).

Adopting Mendler style provides merits of both programming oriented systems
and logic oriented systems. Since Mendler style is elimination based, one can
define all recursive datatypes usually supported in functional programming
languages. In addition, the programs written using Mendler-style recursion
combinators look more similar to the programs written using general recursion
than programs written in Squiggol style.
Since Nax supports only the well-behaved (\ie, strongly normalizing)
Mendler-style recursion combinators, it is safe to construct proofs using them.
In addition, Mendler-style recursion combinators are naturally well-defined
over indexed datatypes, which are essential to express fine-grained program
properties. Mendler style provides type based termination, that is, termination
is a by-product of type checking. Thus, it makes the implementation framework
simple since we do not need extra termination checking theories or algorithm.

Hindley--Milner-style type inference provides a familiar programming experience
to the programmers who are already familiar to functional programming languages.
Nax can infer types for all the programs that involve only regular datatypes,
which are already inferable in Hindley--Milner, without any type annotation.
Nax requires programs involving indexed datatypes to annotate their eliminators
by index transformers, which annotate the relation between the input type index
and the result type. Eliminators of non-recursive datatypes are case expressions
and eliminators of recursive datatypes are Mendler-style recursion combinators.

\subsection{Contributions of identifying open problems}
TODO identified open problems

syntactic conditions form \McvPr


some recursion schemes does not mix well -- sf and pr

is there a useful example for sfcvit

is there a useful example for msfit positive datatypes?


\section{Methodology and Overview}\label{sec:intro:overview}
TODO forward pointers to chapters
chpater organization and why those chapters are there

\begin{comment}
In my dissertation, I will contribute to answering the question
``how does one build a seamless system where programmers
can both write (functional) programs
and formally reason about those programs.''
I will introduce the motivation for pursuing such a system
in \S\ref{sec:intro:motiv},
and I will also discuss foundational work upon which
the approach developed in my thesis is based.

\section{Motivation} \label{sec:motiv}

\section{Thesis}
In this dissertation, we contribute to answering the question of
``how does one build a seamless system where programmers
can both write (functional) programs
and formally reason about those programs.'' In Chapter \ref{ch:relwork},
I will introduce the motivation for pursuing such a system.
I will discuss other approaches to building such a system,
and I will also discuss foundational work upon which
the approach developed in my thesis is based.
The following is my thesis statement, which summarizes my
approach:
\begin{quote}
A language equipped with \emph{term indexed types} and
\emph{Mendler-style recursion combinators} can be 
(1) a basis for \emph{sound and consistent logic}
suitable for reasoning about properties of (functional) programs
and also
(2) a basis for a \emph{simple and expressive programming language}
suitable for writing the (functional) programs to be reasoned about.
\end{quote}

I believe such an approach is promising because, under the design I will
promote, both the logic and the programming language share many
common features. Amongst those features are the two design concepts
of indexed types and Mendler-style recursion combinators.

\emph{Term indexed types} are types indexed by terms. The concept of
term indexed types can be informally understood by contrasting the traditional
(non-indexed) polymorphic list type (\textsf{List} $a$) and a length indexed
(and also polymorphic) list type (\textsf{Vec} $a$ $n$). The polymorphic list
type (\textsf{List} $a$) is parametrized by a type variable ($a:*$), which can
be instantiated to any type. Example instantiations include \textsf{List Nat},
\textsf{List Bool}, and \textsf{List} (\textsf{List Nat}).

A length indexed list type (\textsf{Vec} $a$ $n$) is not only parametrized by
a type variable ($a:*$) but also indexed by a term variable ($n:\textsf{Nat}$),
which can be instantiated to a natural number term. Example instantiations
include \textsf{Vec Int} 3, and \textsf{Vec Bool} $(2+3)$. Types like
\textsf{Vec} are called term indexed types since their type constructors
(\eg, \textsf{Vec}) expect term arguments (\eg, $3$, $(2+3)$). 
With term indexed types, we can express many fine-grained properties of
programs (\eg, reversing a length indexed list preserves its length).

\emph{Mendler-style recursion combinators} are principled recursion schemes,
which are used as induction principles in the logic, and recursion operators
in the programming language. There exist many families of Mendler-style
recursion combinators. Each member of a family performs the same kind of
operation, but is specialized to work over type constructors with
a particular kind. The primitive recursion combinator family was first
discovered by Mendler \cite{Mendler87}. Since that time, several other
kind-dependant families \cite{vene00phd,AbeMatUus03,AhnShe11} have been
discovered to be both expressive and useful.

Mendler-style recursion combinators do have counterparts in the conventional
(sometime called the Squiggol) style. The conventional style combinators are
more widely known and used. But, Mendler-style combinators have several
advantages when compared to conventional style combinators. Mendler-style
recursion combinators have uniform representation over both non-indexed types
and term indexed types, and some families of the Mendler-style recursion
combinators are normalizing for non-positive recursive types as well as
positive recursive types. Detailed discussion on the Mendler-style recursion
combinators can be found in Chapter \ref{ch:mendler}.

Throughout my dissertation, I will support my thesis by designing a series of
language systems of increasing complexity. The goal is that each system can be
used as a \emph{sound} and \emph{consistent} logic, and each system can be
extended to a \emph{simple} and \emph{expressive} (functional) programming
language. Usually, an increase in complexity, leads to a more complete
extension from logic to programming language. Some programming language features
will never be found in a sound logic, and the increase in complexity is designed
to cleanly separate the boundary between the logic and programming language.

Our approach is two layered. we develop an underlying calculus,
and a surface language, which are closely related to each other. I call the
underlying typed lambda calculus System \Fi. It captures the essence of a sound
and consistent logic in the presence of term indexed types. At the same time,
I am designing a simple and expressive language called Nax, whose semantics
is closely related to \Fi\ (in fact, it was designed to be defined in terms of \Fi), but whose
features are restricted in order to make its use more appealing to programmers
than the underlying \Fi\ calculus.

By ``\emph{sound}'', I mean the type soundness of typed lambda calculi
in the usual sense. By ``\emph{consistent}'', I mean not all types are
inhabited by a term. Using the Curry--Howard correspondence, types are
interpreted as propositions, and terms of those types, are interpreted as
proofs of those propositions. Thus, it is in fact the usual sense of
logical consistency -- not all propositions are provable. Since consistency
requires normalization, System \Fi, the language to be developed for the sound
and consistent logic, is indeed a normalizing typed lambda calculus. I will
discuss the features of \Fi\ in detail in Chapter \ref{ch:fi}. Then, in my
dissertation, I will gradually extend \Fi\ to a more expressive calculi \Fixi\
in order to support the Mendler-style combinators of the primitive recursion
family. The features of \Fixi\ are also outlined in Chapters \ref{ch:fi}
and Chapter \ref{ch:fixi}.

By ``\emph{simple}'', I mean that writing programs in the surface language
should require no more complication than writing similar programs in one of
the widely used typed functional programming languages (\eg, Haskell, ML).
In particular, the Nax language we have designed so far, conservatively
extends Hindley-Milner type inference to term indexed types. That is,
all the functional programs involving regular (non-indexed) datatypes, 
whose types are inferable in a Hindley-Milner type system, will need
no additional type annotation to infer their types in Nax. For programs
with richer type structure, involving term indexed types, Nax will require
a small amount of type annotation, in predictable syntactic positions,
which will be required by the language syntax.

By ``\emph{expressive}'', I mean we can write a wide range of examples in Nax.
Since Nax is equipped with Mendler-style recursion combinators, we can write
many useful programs over values with both term indexed types and
negative recursive types, as well as over values with non-indexed types and
positive recursive types. I will discuss the details of Nax
in Chapter \ref{ch:nax}.

However, we cannot express all the programs in Nax. For example,
non-terminating programs using general recursion are not expressible since
Nax is a normalizing language. We know that Nax is normalizing, because
by design, it will be embeddable into \Fi, which is known to be normalizing.
In other words, Nax programs always terminate and can be interpreted logically.
To extend Nax to a Turing complete programming language, we would need to
extend the language with constructs that cannot be interpreted logically,
such as general recursion. When we add such constructs, and if we still wish
to reason logically about the program properties within the language system,
the type system of the language will need to be extended to keep track of
which parts of a program can be interpreted logically and which parts cannot.
There are other possible extensions to Nax that may not necessarily introduce
non-logical fragments but will make Nax more convenient to program in (\eg,
polymorphism at the kind level, as well as the type level, and exceptions).
I will discuss such possible further extensions to Nax
in Chapter \ref{ch:futwork}.

\end{comment}


