\chapter{Introduction}\label{ch:intro}

\section{TOOD}\label{sec:intro:TODO}

the Curry-Howard correspondence
Mendler-style recursion schemes and term-indexed types

\section{TOOD}\label{sec:intro:TODO}

\section{TOOD}\label{sec:intro:TODO}

\subsection{The Curry-Howard correspondence and Normalization}
\label{sec:intro:prelim} %%% TODO fix the label
One promising approach to designing a system that unifies
logical reasoning and programming is \emph{the Curry-Howard correspondence}.
Howard \cite{Howard69} observed that a typed model of computation
(\ie, a typed lambda calculus) gives an interpretation to a (natural deduction)
proof system (for an intuitionistic logic). More specifically, one can interpret
a type (in the lambda calculus) as a formula (in the logic) and
a term of that type, as a proof for that formula. For instance,
the typing rule for function applications (APP) in a typed lambda calculus
corresponds to Modus Ponens (MP) in a logic:
\[ \inference[(APP)]{\Gamma |- t_1 : A -> B & \Gamma |- t_2 : A}{
	\Gamma |- t_1~t_2 : B}
 ~~~~~~~~
   \inference[(MP)]{A -> B & A}{B}
\]
As you can see above, combining terms ($t_1$ and $t_2$) to build a new term
($t_1~t_2$) can be interpreted as combining proofs for formulae
($A -> B$ and $A$), to construct a proof for a new formula ($B$).
More generally, we may expect that programming (\ie, building larger terms)
corresponds to constructing larger proofs only when the typed lambda calculi
meets certain standards -- \emph{type soundness} and \emph{normalization}.

The Curry-Howard correspondence is a promising approach to designing a
unified system for both logical reasoning and programming. Only one language
system is needed for both the logic and the programming language. An
alternate approach is to use an external logical language to talk about
programs as the objects that the logic reasons about. In this approach, one
has the obligation to argue that the soundness of the logic, with respect to
the programming language semantics, holds.

Under the Curry-Howard correspondence, the logic is internally related to the
semantics of program -- there is no need to argue for the soundness of the
logic,  externally outside of the programming language system. The soundness
of the logic follows directly from the type soundness of the language under
the Curry-Howard correspondence.

Let us consider a proposition to be true
(or, valid) when it has a canonical (\ie, cut-free) proof.
That is, there is a program, whose type is the proposition under
consideration, and that program has a normal form. 
By type soundness, any term,
of that type, will preserve its type during the reduction steps. Thus
reduction preserves truthfulness. If we assume
that the language is normalizing (\ie, every well-typed term reduces to
a normal form), then any term of that type which is a non-canonical proof,
implies the existence of a canonical proof, which in turn implies that
the proposition specified by the type is indeed true. That is, all provable
propositions are valid (\ie, the logic is sound) when the language is
\emph{type sound} and \emph{normalizing}.

\emph{Normalization} is also essential for the consistency of the logic.
For the lambda calculus to be interpreted as a \emph{consistent} logic,
there must be no diverging terms. A diverging term (\ie, a term that does
not have a normal form) may inhabit any arbitrary type. Thus, a diverging term
can be a proof for any proposition under the Curry-Howard correspondence.
General purpose functional programming languages (\eg, Haskell and ML), that
support unrestricted general recursion, cannot be interpreted as a consistent
logic, since they allow diverging terms (non-terminating programs).
For example, a diverging Haskell definition $\textit{loop} = \textit{loop}$
can be given an arbitrary type such as
$\textit{loop}\mathrel{::}\textit{Bool}$,
$\textit{loop}\mathrel{::}\textit{Int} -> \textit{Bool}$,
and even $\textit{loop}\mathrel{::}\forall a. a$, which is a proof of false.


Therefore, useful logical reasoning systems based on the Curry-Howard
correspondence (\eg, Coq, Agda) never support language features that can
lead to diverging terms. For example, in both Coq and Agda,
unrestricted general recursion (at term level) is not supported. 
Instead, these logical reasoning systems
often provide principled recursion schemes over recursive types that are
guaranteed to normalize. 

Recursive types (\ie, recursion at type level)
can also lead to diverging terms when they are not restricted carefully.
Many of the conventional logical reasoning systems, based on
Curry-Howard correspondence, restrict recursive types in a way,
which is not an ideal design choice, if one's goal is a unified system for
logic and programming. My approach explores another design space not yet
completely explored. We introduce both approaches to restricting recursive
types to ensure normalization in the following two subsections.


\subsection{Restriction on recursive types for normalization}
\label{sec:relwork:other} %% TODO fix label
We have argued that normalization is essential for logical reasoning systems
based on the Curry-Howard correspondence. One challenge to the successful
design of such systems is how to restrict recursion at the type level
so that normalization of terms is preserved. 
There are two different
design choices illustrated in Figure \ref{fig:approaches}. 
The conventional approach restricts the formation
of recursive types (\ie, the restriction is in datatype definition), and
the Mendler-style approach restricts the elimination
of the values of recursive types (\ie, the restriction is in pattern matching).

\begin{figure}
{\centering
\begin{tabular}{p{3cm}|p{12.5cm}}
\parbox{3cm}{~~Functional\\programming\\$~~~~$language} &
\parbox{12.5cm}{
 kinding:~
  \inference[($\mu$-form)]{\Gamma |- F : * -> *}{\Gamma |- \mu F : *} \\
 \\
 typing:\quad
  \inference[($\mu$-intro)]{\Gamma |- t : F (\mu F)}{\Gamma |- \In~t:\mu F} ~~~~
  \inference[($\mu$-elim)]{\Gamma |- t : \mu F}{\Gamma |- \unIn~t : F (\mu F)}\\
 \\
 reduction:
  \inference[(\unIn-\In)]{}{\unIn~(\In~t) \rightsquigarrow t}
} \\
\\ \hline\hline
\parbox{3cm}{$~$Conventional\\$~~~$approach for\\consistent logic} &
\parbox{12.5cm}{$\phantom{a}$\\
 kinding:~
  \inference[($\mu$-form$^{+}$)]{ \Gamma |- F : * -> * 
                           & \mathop{\mathsf{positive}}(F)}
                           {\Gamma |- \mu F : *} \\
 \\
 typing:~
  \text{{\small($\mu$-intro)} and {\small($\mu$-elim)}
                same as functional language} \\
  \[\inference[(\It)]{\Gamma |- t : \mu F & \Gamma |- \varphi : F A -> A}
                     {\Gamma |- \It~\varphi~t : A}\]
 reduction:~ \text{{\small(\unIn-\In)} same as functional language}
  \[\inference[(\It-\In)]{}{\It~\varphi~(\In~t) \rightsquigarrow
                            \varphi~(\textsf{map}_F~(\It~\varphi)~t)}\]
}
\\ \hline
\parbox{3cm}{Mendler-style\\$~~$approach for\\consistent logic} &
\parbox{12.5cm}{$\phantom{a}$\\
 kinding:~ \text{{\small($\mu$-form)} same as functional language} \\
 \\
 typing:~
  \text{{\small($\mu$-intro)} same as functional language}
  \[\inference[(\MIt)]
     { \Gamma |- t : \mu F &
       \Gamma |- \varphi : \forall X . (X -> A) -> F X -> A}
     {\Gamma |- \MIt~\varphi~t : A} \]
 reduction:~
  \inference[(\MIt-\In)]
     {}
     {\MIt~\varphi~(\In~t) \rightsquigarrow \varphi~(\MIt~\varphi)~t}
}
\end{tabular} }
\caption{Two different approaches to designing a logic
         (in contrast to functional languages)}
\label{fig:approaches}
\end{figure}

\paragraph{Recursive types in functional programming languages.}
Let us start with a review of the theory of recursive types used
in functional programming languages. Here, the term
language is not expected to be normalizing, so restrictions are few.

Just as we can capture the essence of unrestricted general recursion at term
level, by a fix point operator (usually denoted by \textsf{Y} or \textsf{fix}),
we can capture the essence of recursive types by the
use of fix point operator, $\mu$, at type level. 
The rules for the formation {\small($\mu$-form)},
introduction {\small($\mu$-intro)}, and elimination {\small($\mu$-elim)} of
the recursive type operator $\mu$ are described in Figure \ref{fig:approaches}.
We also need a reduction rule {\small(\unIn-\In)}, which relates \In,
the data constructor for recursive types, and \unIn, the destructor for
recursive types, at the term level.

Surprisingly (perhaps), the recursive {\em type} operator,\ $\mu$, as described in
Figure \ref{fig:approaches}, is already powerful enough to express 
non-terminating programs, even without introducing the recursive {\em term}
operator, \textsf{fix}, to the language. We illustrate this below. First a 
short reminder of how a fix point at the term level operates. The typing rule
and the reduction rule for \textsf{fix} can be given as follows:
\[ \text{typing:}~ \inference{\Gamma |- f : A -> A}{\textsf{fix}\,f : A}
 \qquad\qquad
   \text{reduction}:~ \textsf{fix}\,f \rightsquigarrow f(\textsf{fix}\,f)
\]
We can actually implement \textsf{fix}, using $\mu$, as follows
(using some Haskell-like syntax):
\begin{align*}
& \textbf{data}~T\;a\;r = C\;(r -> a) \quad
          \texttt{-}\texttt{-}~\text{\small a non-recursive datatype} \\
& w \,:\, \mu(T\;a) -> a ~~ \qquad \qquad
          \texttt{-}\texttt{-}~\text{\small an encoding of the untyped
                                     $(\lambda x.x\;x)$
                                     in a typed language}~ \\
& w = \lambda x . \,\textbf{case}~\unIn~x~\textbf{of}~C\;f -> f\;x \\
& \textsf{fix} \,:\, (a -> a) -> a \qquad \qquad
          \texttt{-}\texttt{-}~\text{\small an encoding of 
                                     $(\lambda f.(\lambda x.f(x\;x))\,
                                                 (\lambda x.f(x\;x)))$} \\
& \textsf{fix} = \lambda f. (\lambda x. f (w\;x))\,(\In(C(\lambda x. f (w\;x))))
\end{align*}

Thus, to avoid the loss of termination guarantees, we need to alter the rules
for $\mu$, in someways, to ensure a consistent logic. One way, is to restrict
the rule {\small $\mu$-form}; the other way, is to restrict the rule
{\small $\mu$-elim}. Once we decide which of these two alterations of the
rules we will use, the design of principled recursion combinators (\eg, \It\
for the former and \MIt\ for the latter) follows from that choice.

\paragraph{Recursive types in the conventional approach to consistent logic.}
In the conventional approach, the formation (\ie, datatype definition) of
recursive types is restricted, but arbitrary elimination (\ie, pattern matching)
over the values of recursive types is allowed. In particular, the formation of
negative recursive types is restricted. Only positive recursive types are
supported. Thus, in Figure \ref{fig:approaches}, we have a restricted version of
the formation rule {\small($\mu$-form$^{+}$)} has an additional condition that
require $F$ to be positive. The other rules {\small($\mu$-intro)},
{\small($\mu$-elim)}, and {\small(\unIn-\In)} remain the same as for
functional languages. Since we have restricted the recursive types
at the type level and we do not have general recursion at the term level,
the language is indeed normalizing. However, we can neither write
interesting (\ie, recursive) programs that involves recursive types nor
inductively reason about those programs, unless we have principled recursion
schemes that are guaranteed to normalize. One such recursion scheme is called
iteration (\aka\ catamorphism). The typing rules for the conventional iteration
\It\ are illustrated in Figure \ref{fig:approaches}. Note, we have the typing
rule {\small(\It)} and the reduction rule {\small(\It-\In)} for \It\,
in addition to the rules for the recursive type operator $\mu$.

\paragraph{Recursive types in the Mendler-style approach to consistent logic.}
In the Mendler-style approach, we allow arbitrary formation
(\ie, datatype definition) of recursive types, but we restrict
the elimination (\ie, pattern matching) over the values of recursive types. 
The formation rule {\small($\mu$-form)} remains the same as
for functional languages. That is, we can define arbitrary recursive types,
both positive and negative. However, we no longer have the elimination
rule {\small($\mu$-elim)}. That is, we are not allowed to pattern match over
the values of recursive types in the normal fashion. We can only pattern match
over the values of recursive types through the Mendler-style recursion
combinators. The rules for the Mendler-style iteration combinator \MIt\
are illustrated in Figure \ref{fig:approaches}.
Note, there are no rules for \unIn\ in the Mendler-style approach.
The typing rule {\small($\mu$-elim)} is replaced by {\small(\MIt)} and
the reduction rule {\small(\unIn-\In)} is replaced by {\small(\MIt-\In)}.
More precisely, the typing rule {\small \MIt} is both an elimination rule
for recursive types and a typing rule for the Mendler-style iterator.
You can think of the rule {\small(\MIt)} as replacing both the elimination rule
{\small($\mu$-elim)} and the typing rule for conventional iteration
{\small(\It)}, but in a safe way that guarantees normalization.

\subsection{Justification of the Mendler-style as a design choice.}
We choose to base my approach to the design of a seamless synthesis of both
logic and programming on the Mendler-style. It restricts the elimination (\ie,
pattern matching) over values of recursive types, rather restricting the
formation (\ie, datatype definition) of recursive types (a more conventional
approach). The impact of this design choice is that it enables the logic to
include all datatype definitions that are used in functional programming
languages.

Functional programming promotes ``functions as first class values''.
It is natural to pass functions as arguments and embed functions into
(recursive) datatypes. If embedding functions in datatypes is allowed,
we can embed a function whose domain is the very type we are defining.
For example, the recursive datatype definition
$\mathbf{data}~T = C\;(T -> \textit{A})$ in Haskell is such a recursive
datatype definition. Such datatypes are called negative recursive datatypes
since the recursive occurrence $T$ appears in a negative position.
We say that $T$ is in a negative position, since $(T -> A)$ is analogous to
$(\neg T \land A)$ when we think of $->$ as a logical implication. There exist
both interesting and useful examples in functional programs. I will
introduce several such examples, and discuss them, in my dissertation.
%% TODO
TODO fix around here
%% TODO
Recall that the goal of my dissertation (quoting again from \S\ref{sec:intro})
is to contribute to answering the question of {\em how does one build a
seamless system where programmers can both write (functional) programs and
formally reason about those programs}. Under the Curry-Howard correspondence,
to formally reason about a program, the logic needs to refer to the type of
the program, since the type, interpreted as a proposition, describes its
properties. Since the Mendler-style approach does not restrict recursive
datatype definitions, we can directly refer to the types of programs that use
negative recursive types.

The Mendler-style is a promising approach to building a unified system because
all the recursive types, both positive and negative, are definable in the
logic. Although the conventional approach is widely followed in the design of
formal reasoning systems based on the Curry-Howard correspondence (\eg, Coq,
Agda), it cannot directly refer to programs that use non-positive recursive
types. One may object that it is possible to indirectly model negative
recursive types in the conventional style, via alternative equivalent
encodings which map negative recursive types into positive ones. But, such
encodings do not meet our goal of designing a seamless unified system for both
programming and reasoning -- programmers should not have to pre-process their
programs in order to reason about them.

Another benefit of the Mendler-style, is that Mendler recursion combinators
are both useful and well-behaved (\ie, guaranteed to normalize) for arbitrary
recursive types. A Mendler combinator is an induction principle
(principled recursion scheme). It would not be meaningful to have
arbitrary recursive types in the logic unless we have useful and well-behaved
induction principles to reason about the programs using those recursive types.
This is especially true for the negative recursive types.

The Mendler-style iteration combinator family, \MIt, is a well-behaved
combinator for both positive and negative recursive types.
For positive recursive types, \MIt\ is as expressive as the conventional style
iteration combinator \It\ (\ie, both can be defined in terms of each other). 
Furthermore, \MIt\ behaves well (\ie, always normalizes), even for negative
recursive types.

There exist other families of Mendler-style recursion combinators,
which are even more useful than \MIt\ for negative recursive types,
some of which we have discovered in during the thesis research. Throughout
this dissertation, we show that the Mendler-style recursion combinators are
indeed useful and well-behaved induction principles. You can find brief
summary of the Mendler-style recursive schemes in this mid-course document
in \S\ref{sec:mendler}. %%% TODO fix this





\section{Contributions}\label{sec:intro:contrib}
This dissertation makes contributions in several areas.
\begin{itemize}
\item[1.]
It organizes and expands the realm of \emph{Mendler-style recursion schemes}
(Part~\ref{part:Mendler}, \ie, Chapter \ref{ch:mendler})

\item[2.] It establishes a meta-theories for \emph{term-indexed types}
        (Part~\ref{part:Calculi}),

\item[3.] It designs a practical language (with an implementation)
	\emph{in the sweet spot} between programming and logical reasoning
	(Part~\ref{part:Nax}), and

\item[4.] It identifies several interesting open problems related to above.
\end{itemize}

\subsection{Contributions related to the Mendler style}
We organize a hierarchy of Mendler-style recursion schemes in two dimensions.
The first dimension is the abstract operations they support. For instance,
the Mendler-style iteration (\MIt) supports a single abstract operation
the recursive call. All the other Mendler-style recursion schemes
support the recursive call and an additional set of abstract operations. 
The second dimension is over the kind of the datatypes they operate over.
For example, \texttt{Nat} has kind $*$, while \texttt{Vec}
has kind $* -> \mathtt{Nat} -> *$. Each recursion scheme is actually a
family of recursion combinators sharing the same term definition
(\ie, uniformly defined) but with different type signatures at each kind.

We expand the realm of Mendler-style recursion schemes in several ways.
First, we report on a new recursion scheme $\MsfIt$, which is useful
for negative datatypes.  Second, we study the termination behaviors
of Mendler-style recursion schemes. Some recursion schemes (\eg, \MIt, \MsfIt)
always terminate for any recursive type, while others (\eg, \McvPr) only
terminate for certain classes of recursive types. Third, we extend
all Mendler-style recursion schemes to be expressive over term-indexed types.
The Mendler style has been studied in the context of \Fw\ (and several
extensions) which can express type-indexed types. To extend Mendler-style
recursion schemes to be expressive over term-indexed types, we report on
several theories for calculi (\Fi\ and \Fixi) that support term indices.
This is another important area of our contribution.

In addition, we develop a better understanding of some existing
Mendler-style recursion schemes. For instance, the existence of
Mendler-style course-of-values recursion (\McvPr) is reported
in the literature, but the calculus that can embed \McvPr\ was unknown.
We embed Mendler-style course-of-values recursion into \Fixi
(or into \Fixw, when we do not consider term-indices).

\subsection{Contributions to the theory of Term-Indexed Types}
Mendler-style recursion schemes have been studies in the context of
polymorphic lambda calculi. For instance, \citet{AbeMatUus03} embedded 
Mendler-style iteration (\MIt) into \Fw\ and \citet{AbeMat04} embedded
Mendler-style primitive recursion (\MPr) into \Fixw. These calculi
support type-indexed types.

To extend the realm of Mendler-style recursion schemes to include
term-indexed types, we extended \Fw\ and \Fixw\ to support term indices.
In Part \ref{part:Calculi}, we present our new calculi
\Fi\ (Chapter \ref{ch:fi}), which extends \Fw\ with term indices, and
\Fixi (Chapter \ref{ch:fixi}), which extends \Fixw\ with term indices.
These calculi have an erasure property that states that well-typed terms
in each calculus are also well typed terms (when erased) in the 
underlying calculus. For instance, any well typed term in \Fi\ is also
a well-typed term in \Fw, and there are no additional well-typed terms
in \Fi\ that are not well-typed in \Fw.

Our new calculi, \Fi\ and \Fixi, are strongly normalizing and
logically consistent. We show strong normalization and logical consistency
using the erasure properties. That is, strong normalization and
logical consistency of \Fi\ and \Fixi\ are inherited from \Fw\ and \Fixw.
Since \Fi\ and \Fixi\ are strong normalizing and logically  consistent,
the Mendler-style recursion schemes that can be embedded into these calculi
are adequate for logical reasoning as well as programming.

\subsection{Contributions in the design of the Nax language}
We design and implement a prototypical language Nax that explores
the sweet spot between programming oriented systems and logic oriented systems.
The language features supported by Nax provide the advantages
of both programming oriented systems and logic oriented systems.
Nax supports both term- and type-indexed datatypes,
rich families of Mendler-style recursion combinators,
and a conservative extension of Hindley--Milner type inference.
We designed Nax so that its foundational theory and
implementation framework could be kept simple.

Term- and type-indexed datatypes can express fine grained program properties
via the Curry--Howard correspondence, as in logic oriented systems. Although
not as flexible as full-fledged dependent types, indexed datatypes can
still express program invariants, such as type preserving compilation,
and size invariants on data structures. Index types can simulate much of what
dependent types can do using singleton types. Since Nax has only erasable
indices, the foundational theory can be kept simple, and it supports
features that have the advantages of programming oriented systems 
(\eg, type inference, arbitrary recursive datatypes).

Adopting Mendler style provides merits of both programming oriented systems
and logic oriented systems. Since Mendler style is elimination based, one can
define all recursive datatypes usually supported in functional programming
languages. In addition, the programs written using Mendler-style recursion
combinators look more similar to the programs written using general recursion
than programs written in Squiggol style.
Since Nax supports only the well-behaved (\ie, strongly normalizing)
Mendler-style recursion combinators, it is safe to construct proofs using them.
In addition, Mendler-style recursion combinators are naturally well-defined
over indexed datatypes, which are essential to express fine-grained program
properties. Mendler style provides type based termination, that is, termination
is a by-product of type checking. Thus, it makes the implementation framework
simple since we do not need extra termination checking theories or algorithm.

Hindley--Milner-style type inference provides a familiar programming experience
to the programmers who are already familiar to functional programming languages.
Nax can infer types for all the programs that involve only regular datatypes,
which are already inferable in Hindley--Milner, without any type annotation.
Nax requires programs involving indexed datatypes to annotate their eliminators
by index transformers, which annotate the relation between the input type index
and the result type. Eliminators of non-recursive datatypes are case expressions
and eliminators of recursive datatypes are Mendler-style recursion combinators.

\subsection{Contributions of identifying open problems}
TODO identified open problems

syntactic conditions form \McvPr


some recursion schemes does not mix well -- sf and pr

is there a useful example for sfcvit

is there a useful example for msfit positive datatypes?


\section{Organization of the Chapters}\label{sec:intro:org}
TODO

\begin{comment}
In my dissertation, I will contribute to answering the question
``how does one build a seamless system where programmers
can both write (functional) programs
and formally reason about those programs.''
I will introduce the motivation for pursuing such a system
in \S\ref{sec:motiv},
and I will also discuss foundational work upon which
the approach developed in my thesis is based.

\section{Motivation} \label{sec:motiv}

\section{Thesis}
In my dissertation, I will contribute to answering the question
``how does one build a seamless system where programmers
can both write (functional) programs
and formally reason about those programs.'' In Chapter \ref{ch:relwork},
I will introduce the motivation for pursuing such a system.
I will discuss other approaches to building such a system,
and I will also discuss foundational work upon which
the approach developed in my thesis is based.
The following is my thesis statement, which summarizes my
approach:
\begin{quote}
A language equipped with \emph{term indexed types} and
\emph{Mendler-style recursion combinators} can be 
(1) a basis for \emph{sound and consistent logic}
suitable for reasoning about properties of (functional) programs
and also
(2) a basis for a \emph{simple and expressive programming language}
suitable for writing the (functional) programs to be reasoned about.
\end{quote}

I believe such an approach is promising because, under the design I will
promote, both the logic and the programming language share many
common features. Amongst those features are the two design concepts
of indexed types and Mendler-style recursion combinators.

\emph{Term indexed types} are types indexed by terms. The concept of
term indexed types can be informally understood by contrasting the traditional
(non-indexed) polymorphic list type (\textsf{List} $a$) and a length indexed
(and also polymorphic) list type (\textsf{Vec} $a$ $n$). The polymorphic list
type (\textsf{List} $a$) is parametrized by a type variable ($a:*$), which can
be instantiated to any type. Example instantiations include \textsf{List Nat},
\textsf{List Bool}, and \textsf{List} (\textsf{List Nat}).

A length indexed list type (\textsf{Vec} $a$ $n$) is not only parametrized by
a type variable ($a:*$) but also indexed by a term variable ($n:\textsf{Nat}$),
which can be instantiated to a natural number term. Example instantiations
include \textsf{Vec Int} 3, and \textsf{Vec Bool} $(2+3)$. Types like
\textsf{Vec} are called term indexed types since their type constructors
(\eg, \textsf{Vec}) expect term arguments (\eg, $3$, $(2+3)$). 
With term indexed types, we can express many fine-grained properties of
programs (\eg, reversing a length indexed list preserves its length).

\emph{Mendler-style recursion combinators} are principled recursion schemes,
which are used as induction principles in the logic, and recursion operators
in the programming language. There exist many families of Mendler-style
recursion combinators. Each member of a family performs the same kind of
operation, but is specialized to work over type constructors with
a particular kind. The primitive recursion combinator family was first
discovered by Mendler \cite{Mendler87}. Since that time, several other
kind-dependant families \cite{vene00phd,AbeMatUus03,AhnShe11} have been
discovered to be both expressive and useful.

Mendler-style recursion combinators do have counterparts in the conventional
(sometime called the Squiggol) style. The conventional style combinators are
more widely known and used. But, Mendler-style combinators have several
advantages when compared to conventional style combinators. Mendler-style
recursion combinators have uniform representation over both non-indexed types
and term indexed types, and some families of the Mendler-style recursion
combinators are normalizing for non-positive recursive types as well as
positive recursive types. Detailed discussion on the Mendler-style recursion
combinators can be found in Chapter \ref{ch:mendler}.

Throughout my dissertation, I will support my thesis by designing a series of
language systems of increasing complexity. The goal is that each system can be
used as a \emph{sound} and \emph{consistent} logic, and each system can be
extended to a \emph{simple} and \emph{expressive} (functional) programming
language. Usually, an increase in complexity, leads to a more complete
extension from logic to programming language. Some programming language features
will never be found in a sound logic, and the increase in complexity is designed
to cleanly separate the boundary between the logic and programming language.

The approach I will use is two layered. I will develop an underlying calculus,
and a surface language, which are closely related to each other. I call the
underlying typed lambda calculus System \Fi. It captures the essence of a sound
and consistent logic in the presence of term indexed types. At the same time,
I am designing a simple and expressive language called Nax, whose semantics
is closely related to \Fi\ (in fact, it was designed to be defined in terms of \Fi), but whose
features are restricted in order to make its use more appealing to programmers
than the underlying \Fi\ calculus.

By ``\emph{sound}'', I mean the type soundness of typed lambda calculi
in the usual sense. By ``\emph{consistent}'', I mean not all types are
inhabited by a term. Using the Curry-Howard correspondence, types are
interpreted as propositions, and terms of those types, are interpreted as
proofs of those propositions. Thus, it is in fact the usual sense of
logical consistency -- not all propositions are provable. Since consistency
requires normalization, System \Fi, the language to be developed for the sound
and consistent logic, is indeed a normalizing typed lambda calculus. I will
discuss the features of \Fi\ in detail in Chapter \ref{ch:fi}. Then, in my
dissertation, I will gradually extend \Fi\ to a more expressive calculi \Fixi\
in order to support the Mendler-style combinators of the primitive recursion
family. The features of \Fixi\ are also outlined in Chapters \ref{ch:fi}
and Chapter \ref{ch:fixi}.

By ``\emph{simple}'', I mean that writing programs in the surface language
should require no more complication than writing similar programs in one of
the widely used typed functional programming languages (\eg, Haskell, ML).
In particular, the Nax language we have designed so far, conservatively
extends Hindley-Milner type inference to term indexed types. That is,
all the functional programs involving regular (non-indexed) datatypes, 
whose types are inferable in a Hindley-Milner type system, will need
no additional type annotation to infer their types in Nax. For programs
with richer type structure, involving term indexed types, Nax will require
a small amount of type annotation, in predictable syntactic positions,
which will be required by the language syntax.

By ``\emph{expressive}'', I mean we can write a wide range of examples in Nax.
Since Nax is equipped with Mendler-style recursion combinators, we can write
many useful programs over values with both term indexed types and
negative recursive types, as well as over values with non-indexed types and
positive recursive types. I will discuss the details of Nax
in Chapter \ref{ch:nax}.

However, we cannot express all the programs in Nax. For example,
non-terminating programs using general recursion are not expressible since
Nax is a normalizing language. We know that Nax is normalizing, because
by design, it will be embeddable into \Fi, which is known to be normalizing.
In other words, Nax programs always terminate and can be interpreted logically.
To extend Nax to a Turing complete programming language, we would need to
extend the language with constructs that cannot be interpreted logically,
such as general recursion. When we add such constructs, and if we still wish
to reason logically about the program properties within the language system,
the type system of the language will need to be extended to keep track of
which parts of a program can be interpreted logically and which parts cannot.
There are other possible extensions to Nax that may not necessarily introduce
non-logical fragments but will make Nax more convenient to program in (\eg,
polymorphism at the kind level, as well as the type level, and exceptions).
I will discuss such possible further extensions to Nax
in Chapter \ref{ch:futwork}.

\end{comment}


