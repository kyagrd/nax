\section{The Hindley-Milner type system} \label{sec:hm}

\citet{Hindley69} discovered that there exists a unique principal type scheme
for every object in a combinatory logic. \citet{Milner78} rediscovered this
in the setting of a polymorphic lambda calculus, while he was devising
an algorithm, called the algorithm $W$, which infers a most general
type scheme (\aka\ principal type scheme) for a Curry-style term.
\citet{Damas85} developed detailed theories on Milner's polymorphic
lambda calculus and the type inference algorithm $W$. The type system
for Milner's polymorphic lambda calculus \cite{Milner78,DamMil82,Damas85}
is also known as the Hindley-Milner type system (HM),
the Damas-Hindley-Milner type system (DHM), or let-polymorphism.

The syntax of Milner's polymorphic lambda calculus and its the typing rules
are illustrated in Figure \ref{fig:hm}, and the type inference algorithm $W$
is illustrated in Figure \ref{fig:algW}. We describe the syntax in
\S\ref{sec:hm:syntax}, the typing rules in \S\ref{sec:hm:dectyrule} and
\S\ref{sec:hm:syntyrule}, and the type inference algorithm in \S\ref{sec:hm:W}.
Note, that there are two sets of typing rules.
The declarative typing rules (\S\ref{sec:hm:dectyrule}) are suited for
reasoning about the soundness of typing.
The syntax directed typing rules (\S\ref{sec:hm:syntyrule}) are suited
for reasoning about the properties of the type inference algorithm $W$
(\S\ref{sec:hm:W}).

\begin{figure}
\begin{singlespace}\small
\small
\begin{align*}
&\textbf{Term}&
t,s&~::= ~ x          
    ~  | ~ \l x    . t 
    ~  | ~ t ~ s       
    ~  | ~ \<let> x=s \<in> t
\\
&\textbf{Type (or, monotype)}&
A,B&~::= ~ A -> B
    ~  | ~ \iota
    ~  | ~ X
\\
&\textbf{Type scheme (or, polytype)}&
\sigma&~::= ~ \forall X.\sigma
       ~  | ~ A
\\
&\textbf{Typing context}&
\Gamma&~::= ~ \cdot 
       ~  | ~ \Gamma, x:\sigma \quad (x\notin \dom(\Gamma))
\end{align*}
\[ \textbf{Type scheme ordering (or, generic instantiation)} \quad \framebox{$\sigma \sqsubseteq \sigma'$}\]
\[ \qquad \inference{X_1',\dots,X_m'\notin\FV(\forall X_1\dots X_n.A)}
             {\forall X_1\dots X_n.A \;\sqsubseteq\;
	      \forall X_1'\dots X_m'.\,A[B_1/X_1]\cdots[B_n/X_n]} \]
$\!\!\!\!\!\!\!\!\!\!$
\begin{align*}
&\textbf{Delcarative typing rules}&\quad
&\textbf{Syntax-directed typing rules}
	\\
& \qquad\framebox{$\Gamma |- t : \sigma$}
&
&~\qquad\framebox{$\Gamma |-s t : A$}
	\\
& \inference[\sc Var]{x:\sigma \in \Gamma}{\Gamma |- x:\sigma} &
& \inference[\sc Var$_s$]{x:\sigma \in \Gamma & \sigma \sqsubseteq A}
 	                 {\Gamma |-s x:A} \\
& \inference[\sc Abs]{\Gamma,x:A |- t : B}{\Gamma |- \l x   .t : A -> B} &
& \inference[\sc Abs$_s$]{\Gamma,x:A |-s t:B}{\Gamma |-s \l x   .t : A -> B} \\
& \inference[\sc App]{\Gamma |- t : A -> B & \Gamma |- s : A}
		     {\Gamma |- t~s : B} &
& \inference[\sc App$_s$]{\Gamma |-s t : A -> B & \Gamma |-s s : A}
		         {\Gamma |-s t~s : B} \\
& \inference[\sc Let]{\Gamma |- s : \sigma & \Gamma,x:\sigma |- t : B}
		     {\Gamma |- \<let> x=s \<in> t : B} &
& \inference[\sc Let$_s$]
            {\Gamma |-s s : A & \Gamma,x:\overline{\Gamma}(A) |-s t : B}
	    {\Gamma |-s \<let> x=s \<in> t : B} \\
& \inference[\sc Inst]{\Gamma |- t : \sigma & \sigma \sqsubseteq \sigma'}
		      {\Gamma |- t : \sigma'} &
&\quad\qquad \begin{smallmatrix}\overline{\Gamma}(A)=\forall\vec{X}.A&
			 ~\text{where}~\vec{X}=\FV(A)\setminus\FV(\Gamma)
		 \end{smallmatrix}
		 \\
& \inference[\sc Gen]{\Gamma |- t : \sigma}
		     {\Gamma |- t : \forall X.\sigma} ~ (X \notin\FV(\Gamma))
\end{align*}
\end{singlespace}
\caption{Milner's polymorphic lambda calculus}
\label{fig:hm}
\end{figure}

\subsection{Syntax}\label{sec:hm:syntax}
The syntax of terms include the usual Curry-style terms
($x$, $\l x.t$, and $t\;s$) and let-terms ($\<let> x=s \<in> t$).
A let term, $\<let> x=s \<in> t$, is semantically equivalent to
$(\l x.t)\,s$. That is, $\<let> x=s \<in> t$ is a syntactic sugar
for $(\l x.t)\,s$ in terms of reduction\footnote{The reduction rules for
	for the terms of HM are exactly the same as the reduction rules for
	Curry-style terms in the previous sections, once we desugar
	all the let terms.}
However, let-terms are significant in the typing rules, since a let-term can
introduce a polymorphic type scheme into the typing context. We will discuss
further details of typing let-terms (the \rulename{Let} rule) later on, when
we explain the typing rules.

The syntax of types (or, monotypes) include all the types in the STLC
($A -> B$ and $\iota$) and type variables ($X$).
The syntax of type schemes (or, polytypes) are similar to
the polymorphic types of System \F, but universal quantification must appear
only at the top level. Type schemes are either universal quantifications over
other type schemes ($\forall X.\sigma$) or (mono)types ($A$).
Typing contexts ($\Gamma$) keep track of each term variable and
its associated type scheme ($x:\sigma$).

The ordering between two type schemes $\sigma \sqsubseteq \sigma'$,
defined in Figure \ref{fig:hm}, means that $\sigma$ is more general
than or equivalent to $\sigma'$. The ordering relation $\sqsubseteq$
comes from \citet{DamMil82}, which is also known as generic instantiation:
$\sigma'$ is called a generic instance of $\sigma$
when $\sigma \sqsubseteq \sigma'$. The shorthand notation
$\forall X_1\dots X_n.A$ stands for consecutive universal quantification
of $n$ variables. For instance, $\forall X_1\,X_2\,X_3.A$
is a shorthand for $\forall X_1.\forall X_2.\forall X_3.A$.

Two type schemes $\sigma$ and $\sigma'$ are equivalent
when $\sigma \sqsubseteq \sigma'$ and $\sigma' \sqsubseteq \sigma$.
This coincides with $\alpha$-equivalence (\eg, $\forall X.X -> X$ is
equivalent to $\forall X'. X' -> X$). In fact, we can derive
$\alpha$-equivalence as a special case of the type scheme ordering rule,
where $n=m$ and $B_i=X_i'$ for each $i$ from $1$ to $n$.

The usual \empty{instantiation} (\ie, substitution of quantified variables
with types) falls under the type scheme ordering rule. For instance,
$ (\forall X_1\,X_2.X_1 -> X_2) \sqsubseteq
  (\forall X_2.\iota -> X_2) \sqsubseteq (\iota -> \iota) $.
Here, we instantiate $X_1$ with $\iota$,
and then, instantiate $X_2$ with $\iota$.
In such cases of $\sigma\sqsubseteq\sigma'$, we can call $\sigma'$ an instance,
as well as generic instance, of $\sigma$. For example, $\iota\to\iota$ is
an instance of $\forall X_2.\iota\to X_2$ and $\forall X_1\,X_2.X->X_2$, and,
$\iota\to\iota$ and $\forall X_2.\iota\to X_2$ are instances of
$\forall X_1\,X_2.X_1->X_2$.

More generally, we say that $\sigma'$ is a \empty{generic instance} of $\sigma$
when $\sigma \sqsubseteq \sigma'$, since the relation $\sqsubseteq$
is more than $\alpha$-equivalence and instantiation.
The type scheme ordering rule allows quantifying newly introduced
variables in $\sigma'$, which do not appear free in $\sigma$.
For example, consider the two generic instances of $\forall X.X -> X$ below:
\begin{align*}
\forall X.X -> X \sqsubseteq\;\,& (X'-> X')-> (X'-> X') \\
\forall X.X -> X \sqsubseteq\;\,& \forall X'.(X'-> X')-> (X'-> X')
\end{align*}
The former, $(X'-> X')-> (X'-> X')$, is an instance of $\forall X.X -> X$
instantiating $X$ to $(X'-> X')$. However, the latter,
$\forall X'.(X'-> X')-> (X'-> X')$, is not an instance
but a generic instance of $\forall X.X-> X$ because
the newly introduced variable $X'$ is universally quantified.

There is a difference between the (mono)type $(X'-> X')-> (X'-> X')$,
where $X'$ is free, and the type scheme $\forall X'.(X'-> X')-> (X'-> X')$,
where $X'$ is universally quantified.
A function of the monomorphic type $(X'-> X')-> (X'-> X')$
can only be applied to functions of the same type in one program, but
a function of the polymorphic type scheme $\forall X'.(X'-> X')-> (X'-> X')$
can be applied to functions of many different types in one program.
For example, consider a typing context $\Gamma$ such that\footnote{
	For an intuitive explanation, we assume \texttt{int} and \texttt{string}
	to be existing ground types although our formal definition of HM
	in Figure \ref{fig:hm} only has the void type $\iota$ as
	the ground type for simplicity.} \vspace*{-1em}\\ 
\begin{minipage}{.3\linewidth}
\begin{align*}
\!\!\!\!\!\!\!\!\!\!
\textit{square} : \;\quad~\texttt{int} -> \texttt{int} ~\quad\; \in \Gamma \\
\!\!\!\!\!\!\!\!\!\!
\textit{revstr} : \texttt{string} -> \texttt{string} \in \Gamma
\end{align*}
\end{minipage}
\begin{minipage}{.4\linewidth}
\begin{align*}
\textit{Id}_{->}^{\,\textit{mon}} : \quad (X'-> X')-> (X'-> X') \quad \in \Gamma \\
\textit{Id}_{->}^{\,\textit{poly}} : \forall X'.(X'-> X')-> (X'-> X') \in \Gamma
\end{align*}
\end{minipage} \vspace*{1em} \\
In other words, four function names with the types assigned as above
are available in the context. Under this typing context $\Gamma$,
it is possible to apply $\textit{Id}_{->}^{\,\textit{mon}}$,
the monomorphic identity function over endofunctions,
to both \textit{square} and \textit{revstr} as below,
as long as we do not try to apply $\textit{Id}_{->}^{\,\textit{mon}}$ to both
of them in the same program.\footnote{A program is just a term, but it sounds
like a more practical example.} For example,
\[ \Gamma |-
	(\textit{Id}_{->}^{\,\textit{mon}}\;\textit{square}) :
	\texttt{int} -> \texttt{int}
\]
\[ \Gamma |-
	(\textit{Id}_{->}^{\,\textit{mon}}\;\textit{revstr}) :
	\texttt{string} -> \texttt{string}
\]
However, it is impossible to derive a type for a program, which which applies
$\textit{Id}_{->}^{\,\textit{mon}}$ to both \textit{square} and \textit{revstr} 
in one program, since there is no solution for inconsistent equations
$X'=\mathtt{int}$ and $X'=\mathtt{string}$.
\begin{align*}
\Gamma |- \;
& \dots (\textit{Id}_{->}^{\,\textit{mon}}\;\textit{square}) \dots \\
& \dots (\textit{Id}_{->}^{\,\textit{mon}}\;\textit{revstr}) \dots
~:~ \text{this is a type error}
\end{align*}
On the other hand, we can apply $\textit{Id}_{->}^{\,\textit{poly}}$,
the polymorphic identity function over endofunctions, to both
\textit{square} and \textit{revstr} even in one program, since
the universally quantified type variable $X'$ can be instantiated
to many different types including \texttt{int} and \texttt{string}.
\[ \Gamma |-
	(\textit{Id}_{->}^{\,\textit{poly}}\;\textit{square}) :
	\texttt{int} -> \texttt{int}
\]
\[ \Gamma |-
	(\textit{Id}_{->}^{\,\textit{poly}}\;\textit{revstr}) :
	\texttt{string} -> \texttt{string}
\]
\begin{align*}
\Gamma |-\;
& \dots (\textit{Id}_{->}^{\,\textit{poly}}\;\textit{square}) \dots \\
& \dots (\textit{Id}_{->}^{\,\textit{poly}}\;\textit{revstr}) \dots
~:~ \text{this can be type correct}
\end{align*}

\subsection{Declarative typing rules}\label{sec:hm:dectyrule}
The declarative typing rules deduce a type scheme for a given term under
a typing context ($\Gamma |- t : \sigma$). The type scheme ($\sigma$)
deduced for the given term ($t$) under the typing context ($\Gamma$) may not
be unique. For example,
\begin{align*}
	&\cdot |- \l x.x: \iota -> \iota \\
	&\cdot |- \l x.x: X -> X \\
	&\cdot |- \l x.x: (X -> X) -> (X -> X) \\
	&\cdot |- \l x.x: \forall X.X -> X \\
	&\cdot |- \l x.x: \forall X.(X -> X) -> (X -> X) \\
	&\cdot |- \l x.x: \forall X_1 X_2.(X_1 -> X_2) -> (X_1 -> X_2) \\
	&\quad \vdots
\end{align*}
This is expected since terms of HM are Curry style. Recall that
the uniqueness of typing does not hold for lambda calculi with
Curry-style terms. The first three rules \rulename{Var}, \rulename{Abs},
and \rulename{App} are fairly standard. The \rulename{Var} rule deduces
the type scheme of a variable according to the type scheme binding
of the variable in the typing context. The type schemes deduced by
the rules \rulename{Abs} and \rulename{App} are restricted to the form
of (mono)types\footnote{Recall that types are subset of type schemes.}
since the domain and range of functions types are restricted to (mono)types.
The \rulename{Let} rule can introduce polymorphic type schemes into
the typing context. The \rulename{Inst} rule deduces a generic instance
($\sigma'$) of any type scheme ($\sigma$). The \rulename{Inst} rule
is essential when variables with polymorphic type schemes appear in
the rules \rulename{Abs} and \rulename{App}. For instance,
when $t$ is a variable with a polymorphic type scheme in $\Gamma$,
we need to instantiate the type scheme into a type since \rulename{Abs}
and \rulename{App} is restricted to deduce types. A typical usage of
the \rulename{Inst} rule is illustrated below:
\[
\inference[\sc Abs]
  {\inference[Inst]
	{\inference[Var]
		{x':\forall X'.X' -> X' \in x':\forall X'.X' -> X',x:X}
		{x':\forall X'.X' -> X',x:X|- x':\forall X'.X'-> X'}
	}
  	{x':\forall X'.X' -> X',x:X |- x':X' -> X'}}
  {x':\forall X'.X' -> X' |- \l x.x' : X -> (X' -> X')}
\]
The \rulename{Gen} rule deduces a generalization (\ie,
universal quantification) of a type scheme, as long as
the quantified variable does not appear free in the typing context.
The \rulename{Gen} is essential for the \rulename{Let} rule to be useful.
For instance, consider that $s$ is a function that may be polymorphic,
such as the identity function $\l x'.x'$. Recall that the \rulename{Abs} can
only deduce a type without any universal quantification, such as $X -> X$.
Here, we can use the \rulename{Gen} rule to generalize $X -> X$ to
$\forall X.X -> X$, provided that $X$ does not appear free in
the typing context, in order to make $\sigma$ appearing in
the \rulename{Let} rule a polymorphic type scheme, as below:
\[
\inference[\sc Let]
  { \inference[\sc Gen]
	  {\inference[\sc Abs]{\vdots}{\Gamma|- \l x'.x' : X -> X}}
	  {\Gamma|- \l x'.x':\forall X.X-> X}
  & \Gamma,x:\forall X.X-> X |- t : B}
  {\Gamma |- \<let> x = \l x'.x' \<in> t : B}
\]

The soundness of typing is obvious once we observe that HM is a restriction
of the Curry-style System \F\ (\ie, if $\Gamma |- t : \sigma$ in HM, then
$\Delta;\Gamma |- t : \sigma$ in System \F). The terms in HM are exactly
the same as the terms in the Curry-style System \F, if we consider the let-term
as a syntactic sugar. Both types and type schemes in HM are restrictions of
types in System \F. The declarative typing rules are also a restriction of
the typing rules in System \F. The rules \rulename{Var}, \rulename{Abs},
\rulename{App}, and \rulename{Gen} in HM are virtually same as
their counterparts in Systerm \F, which are the rules \rulename{Var},
\rulename{Abs}, \rulename{App}, and \rulename{TyAbs}, respectively.
Thus, all we need to make sure is that the \rulename{Let} rule and
the \rulename{Inst} rule in HM are admissible in System \F.
A single derivation step of \rulename{Let} in HM corresponds to
two derivation steps in System \F\
involving the \rulename{App} and \rulename{Abs} rules,
considering the let-term as a syntactic sugar, as below:
\[\inference[\sc Let]{\Gamma |- s : \sigma & \Gamma,x:\sigma |- t : B}
		     {\Gamma |- \<let> x=s \<in> t : B} 
\]
\[\inference[\sc App]
	{ \inference[\sc Abs]
		{ \Delta |- \sigma
		& \Delta;\Gamma,x:\sigma |- t : B}
		{\Delta;\Gamma |- \l x.t : A -> B}
	& \Delta\Gamma |- s : \sigma }
	{\Delta;\Gamma |- (\l x.t)\;s}
\]
A singe derivation step of \rulename{Inst} in HM corresponds to
multiple derivation steps in System \F\ involving
the rules \rulename{TyAbs} and \rulename{TyApp} rules, as below:
{\small
\begin{multline*}
  \inference[\sc Inst]{\Gamma |- t : \sigma & \sigma \sqsubseteq \sigma'}
		      {\Gamma |- t : \sigma'}
	\quad\text{where}~
	\begin{array}{rl}
		\sigma =& \forall X_1\dots X_n.A ~~~~~~~~~~~~~~~~~~~~~~ \\
	       \sigma' =& \forall X_1'\dots X_m'.\,A[B_1/X_1]\cdots[B_n/X_n]
	\end{array}
 \\ \text{such that}~
   \inference{X_1',\dots,X_m'\notin\FV(\forall X_1\dots X_n.A)}
             {\forall X_1\dots X_n.A \;\sqsubseteq\;
	      \forall X_1'\dots X_m'.\,A[B_1/X_1]\cdots[B_n/X_n]}
\end{multline*}

\begin{align*}
& \inference[\sc TyApp]
	{\Delta;\Gamma |- t : A & \Delta |- A}
	{\Delta;\Gamma |- t : A[B_1/X_1] ~~\,} \\
& \inference[\sc TyApp]
	{ \quad \vdots \qquad\qquad\qquad\qquad\qquad
	& \Delta |- A[B_1/X_1]\cdots[B_{n-1}/X_{n-1}]
	}
	{ \Delta;\Gamma |- t : A[B_1/X_1]\cdots[B_n/X_n] \qquad \qquad
	 \qquad\qquad\qquad\qquad\qquad
 	} \\
& \inference[\sc TyAbs]
	{}
	{\Delta;\Gamma |- t : \forall X_m'.\,A[B_1/X_1]\cdots[B_n/X_n]} ~
	(X_m'\notin\FV(A[B_1/X_1]\cdots[B_n/X_n])) \\
& \qquad\qquad\qquad\qquad\qquad \vdots \\
& \inference[\sc TyAbs]
	{\Delta;\Gamma |- t : \forall X_2'\dots X_m'.\,A[B_1/X_1]\cdots[B_n/X_n]}
	{\Delta;\Gamma |- t : \forall X_1'\dots X_m'.\,A[B_1/X_1]\cdots[B_n/X_n]} ~
	(X_1'\notin\FV\left(\begin{smallmatrix}\forall X_2'\dots X_m'.\\A[B_1/X_1]\cdots[B_n/X_n]\end{smallmatrix}\right)) \\
\end{align*}
} %% end \small

\subsection{Syntax directed typing rules}\label{sec:hm:syntyrule}
The syntax directed typing rules deduce a type, rather than a type scheme,
for a given term under a typing context ($\Gamma |- t : A$). These rules
are syntax directed since there is only one rule to apply for each syntactic
category of terms. Therefore, the typing is unique (up to change of
type variables) for the given term and the typing context. For example,
$\l x.x$ has a unique typing with respect to the syntax directed typing rules,
as below: \[ \cdot |- \l x.x: X -> X \]
The syntax directed typing rules are based on the observation
that the \rulename{Inst} and \rulename{Gen} in the declarative typing rules
are only necessary at the \rulename{Var} and \rulename{Let} rules, respectively.
That is, we only need to apply the \rulename{Inst} rule to the conclusion of
the \rulename{Var} rule, and, we only need to apply the \rulename{Gen} rule to
the first premise ($\Gamma |- s:\sigma$) of the \rulename{Let} rule.
The \rulename{Var$_s$} rule can be understood as a merge of
\rulename{Var} and \rulename{Inst} in one rule.
The \rulename{Abs$_s$} rule and the \rulename{App$_s$} rule remains the same as
their counterparts in the declarative typing rules.
The \rulename{Let$_s$} rule can be understood as a merge of
\rulename{Let} and \rulename{Gen} in one rule.
The notation $\overline{\Gamma}(A)$ appearing in the \rulename{Let$_s$} is
a closure of type $A$ with respect to $\Gamma$. That is, $\overline{\Gamma}(A)$
generalizes $A$ all the free type variables of $A$ except the free variables of
$\Gamma$. The free type variables of $\Gamma$ is defined as:
$\FV(\Gamma) = \bigcup_{x:\sigma\in \Gamma} \FV(\sigma)$.

Syntax directed typing rules are sound (Theorem \ref{thm:sdHMsound})
and complete (Corollary \ref{cor:sdHMcomplete} with respect to
the declarative typing rules.
\begin{theorem}[$|-s$ is sound with respect to $|-$]
$ \inference{\Gamma |-s t : A}{\Gamma |- t : A} $
\label{thm:sdHMsound}
\end{theorem}
\begin{proof}
We will just give an key idea for the proof
since the soundness is rather obvious.
All we need to do is transform any given derivation for $|-s$
into a derivation for $|-$, which is straightforward.

Recall that the \rulename{Var$_s$} rule can be understood as a merge of
\rulename{Var} and \rulename{Inst}. Thus, we can transform any derivation
step using \rulename{Var$_s$} rule into two steps of derivation using
the \rulename{Var} rule, and then applying the \rulename{Inst} rule
to the conclusion of the \rulename{Var} rule.

The \rulename{Abs$_s$} rule and the \rulename{App$_s$} rules are mapped
to the \rulename{Abs} rule and the \rulename{App} rule, respectively.

Recall that the \rulename{Let$_s$} rule can be understood as a merge of
\rulename{Let} and \rulename{Gen}. We can transform any derivation step
using the \rulename{Let$_s$} rule into a series of \rulename{Gen} rules
applied to the first premise of the \rulename{Let} rule, and then applying
the \rulename{Let} rule. Since the definition of the closure
$\overline{\Gamma}(A)$ appearing in the \rulename{Let$_s$} rule
generalizes only the free type variables of $A$, which do not
appear free in $\Gamma$, the condition $X\notin\FV(\Gamma)$ appearing
in the \rulename{Gen} rule holds.
\end{proof}
The completeness of $|-s$ can be shown by proving a stronger theorem
that $|-s$ deduces a most general type.
\begin{theorem}[$|-s$ deduces a most general type]
$ \inference
	{\Gamma |- t : \sigma}
	{\Gamma |-s t : A ~\land~ \overline{\Gamma}(A)\sqsubseteq\sigma} $
\end{theorem}
\begin{proof}
TODO
\end{proof}

\begin{corollary}[$|-s$ is complete with respect to $|-$]
$ \inference{\Gamma |- t : \sigma}{\Gamma |-s t : A} $
\label{cor:sdHMcomplete}
\end{corollary}

\subsection{The type inference algorithm $W$}\label{sec:hm:W}
The type inference algorithm $W$ is sound and complete
with respect to the syntax directed typing rules.

TODO\\
TODO\\
TODO\\
TODO\\
TODO\\
TODO\\
TODO\\
TODO\\
TODO\\
TODO\\

TODO

\begin{figure}
\begin{singlespace}
\[ \inference[\sc Var$_W$]
	{x:\forall X_1\dots X_n.A\in\Gamma \\
	 X_1',\dots,X_n'~\text{fresh}}
        {W(\Gamma,x) ~> (\emptyset,A[X_1'/X_1]\cdots[X_n'/X_n])}
\]
\[ \inference[\sc Abs$_W$]
	{X~\text{fresh} \\
	 W(\Gamma,x:X,t) ~> (S_1,A)}
	{W(\Gamma,x) ~> (S_1,S_1(X -> A))}
\]

\[ \inference[\sc App$_W$]
	{W(\Gamma,s) ~> (S_1,A_1) \\
	 W(S_1 \Gamma,t) ~> (S_2,A_2) \\
	 X~\text{fresh} \\
	 \unify(S_2 A_1,A_2 -> X) ~> S_3 }
	{W(\Gamma,s\;t) ~> (S_3\circ S_2\circ S_1,S_3 X)}
\]

\[ \inference[\sc Let$_W$]
	{W(\Gamma,s) ~> (S_1,A_1) \\
	 W(S_1(\Gamma,x:\overline{S_1\Gamma}(A_1)),t) ~> (S_2,A_2) }
	{W(\Gamma,\<let> x=s \<in> t) ~> (S_2\circ S_1,A_2)}
\]
\end{singlespace}
\caption{The type inference algorithm $W$}
\label{fig:algW}
\end{figure}

There exists a unification algorithm such that


\subsection{Unification}
A single substitution

\begin{figure}
\begin{singlespace}
\textbf{Unification}
\[ \unify(A_1,A_2) = U(\{A_1 =?= A_2\}) \]
\begin{align*}
U(\{A -> B =?= \iota\}\uplus Q) & ~> \text{fail} \\
U(\{\iota =?= A -> B\}\uplus Q) & ~> \text{fail} \\
U(\{\iota =?= \iota\}\uplus Q) & ~> U(Q) \\
U(\{x =?= x\}\uplus Q) & ~> U(Q) \\
U(\{A_1 -> B_1 =?= A_2 -> B_2\}\uplus Q)
	& ~> U(\{A_1 =?= A_2, B_1 =?= B_2\}\uplus Q) \\
U(\{x =?= y\}\uplus Q) & ~> U(\{y =?= x\}\uplus Q) \<when> x>y \\
U(\{A =?= y\}\uplus Q) & ~> U(\{y =?= A\}\uplus Q) \\
                            & \<when> A ~\text{is not a variable} \\
U(\{x =?= A\}\uplus Q) & ~> \text{fail}~ \<when> x\notin\FV(A) \\
U(\{x =?= A\}\uplus Q) & ~> U(\{x =?= A\}\uplus Q[A/x]) \\
			    & \<when> x\in\FV(Q) \\
U(\{x_1 =?= A_1,\dots,x_n =?= A_n\})
	& ~> \{x_1\mapsto A_1,\dots,x_n\mapsto A_n\} \\
	& \<when> x_1,\dots,x_n ~\text{are distinct, and,} \\
	& \qquad\quad x_i\notin\FV(A_j) ~\text{for all $i$ and $j$} \\
\end{align*}

\textbf{Unifier composition}
\begin{quote}
Let $S_1$ and $S_2$ be unifiers. That is,\\
for any $x\in \dom(S_1)$, $x$ does not occur in range of $S_2$, and,\\
for any $x\in \dom(S_1)$, $x$ does not occur in range of $S_2$.

Then, the composition of two unifiers $S_1$ and $S_2$ is defined as follows:
\end{quote}
\[ S_1 \circ S_2 = U(\{ x =?= A \mid x\mapsto A \in S_1 \cup S_2 \}) \]

\end{singlespace}
\caption{The unification algorithm and the composition of unifiers}
\label{fig:algU}
\end{figure}

\cite{Robinson65} TODO

\begin{proposition}[unification of identical types] $U(A,A)=\emptyset$
\label{prop:unifyidentical}
\end{proposition}
\begin{proof}
	%% TODO Easy by induction on the structure of type $A$.
\end{proof}
Note, that unification of identical types always suceeds.

\begin{lemma}[substitution composition is idempotent] \label{lem:compident}
	~\\ \indent
	$S\circ S = S$ \quad (when $\circ$ succeeds)
\end{lemma}
\begin{proof}
We prove by induction on the size of the substitution $S$.
The size of $S$ is defined as the size of its domain (\ie, $|S| = |\dom(S)|$).

When $S$ is empty, then it is trivial since
$\emptyset \circ \emptyset = \emptyset$
by the first equation of the substitution composition in Figure \ref{fig:algU}.

When $S$ is non-empty, we should apply the third equation
since the domains of the left- and right-hand side of the composition
obviously share the same variables. Recall the third equation of
the substitution composition in Figure \ref{fig:algU}:
\begin{align*}
(\{x\mapsto A_1\}\uplus S_1)\circ
(\{x\mapsto A_2\}\uplus S_2)
	&= (S_1\circ S_2) \circ (\{x\mapsto S A_1\}\uplus S) \\
	&\<where> S=U(A_1,A_2)
\end{align*}
Note that $\{x\mapsto A_1\}\uplus S_1 = \{x\mapsto A_2\}\uplus S_2$ in our case.
So, is easy to see that $A_1=A_2$ and $S_1=S_2$ Let us give a new name $S'$
for the substitutions $S_1$ and $S_2$ (\ie, $S'=S_1=S_2$) and a new name $A$
for the two types $A_1$ and $A_2$ (\ie, $A=A_1=A_2$).
By Proposition \ref{prop:unifyidentical}, we know that $S=\emptyset$
and $A=A_1=A_2$ in the above equation.  And, by induction,
we know that $S'\circ S' = S'$ (when composition succeeds).
Using what we know, we can simplify the above equation as follows:
\begin{align*}
(\{x\mapsto A\}\uplus S')\circ
(\{x\mapsto A\}\uplus S') &= S'\circ S' \circ \{x\mapsto A\} \\
			  &= S' \circ \{x\mapsto A\} \\
			  &= S' \uplus \{x\mapsto A\} \\
			  &= \{x\mapsto A\} \uplus S'
\end{align*}
The last two steps of the above simplification rely on the fact that
$x\notin\dom(S')$ (thus, using the second equation of $\circ$)
and $\uplus$ is commutative.

Therefore, $S\circ S = S$ (when composition succeeds).
\end{proof}

\begin{proposition}[composition of identical well-formed substitutions succeds]
	\label{prop:compident}
\begin{quote} $S \circ S$ suceeds when $S$ is well-formed \end{quote}
\end{proposition}
\begin{proof}
As discussed in the proof of the previous lemma,
the computation of $S \circ S$ will only involve
the first and thrid equations of the defintion of $\circ$.
The only source of possible failure is in the third equation calling on $U$.
However, we know that $U$ always suceeds when unifying identical types
(Proposition \ref{prop:unifyidentical}).
\end{proof}

From now on, $S_1 \circ S_2 = S$ means that the composition succeeds and
returns $S$. Similarly, $U(A_1,A_2)=S$ means that the unification succeeds
and returns $S$.

\begin{theorem}[substitution composition is idempotent] ~
	\begin{quote} $S\circ S = S$ for any well-formed $S$ \end{quote}
\end{theorem}
\begin{proof}
	By Lemma \ref{lem:compident} and Proposition \ref{prop:compident}.
\end{proof}

\begin{theorem}[unification is commutative] $ U(A_1,A_2) = U(A_2,A_1) $
	\label{thm:commU}
\end{theorem}
\begin{proof} Easy by induction on the structure of $A_1$ and $A_2$.

The base cases (\ie, $U(\iota,\iota)$, $U(x,x)$, $U(x_1,x_2)$,
			$U(x_1,A_2)$, $U(A_1,x_2)$) are trivial.

In the inductive case $U(A_1 -> B_1, A_2 -> B_2)$, we know that
$U(A_1,A_2) = U(A_2,A_1)$ and $U(B_1,A_2) = U(B_2,B_1)$ by induction.
Therefore,
\begin{align*}
U(A_1 -> B_1, A_2 -> B_2)
	&= U(A_1,A_2) \circ U(B_1,B_2) \\
	&= U(A_2,A_1) \circ U(B_2,B_1) = U(A_2 -> B_2, A_1 -> B_1)
\end{align*}
\end{proof}
TODO have we proved that both sides fail at the same time in the inductive case?



A substitution is well-formed when no variables of its domain
occurs in its range (\ie, $\dom(S)\cap\FV(\ran(S))=\emptyset$).

\begin{proposition}[substitution composition preserves well-formedness] ~
\begin{quote}
	Let $S_1$ and $S_2$ be well-formed substitutions.\\
	If $S_1\circ S_2=S$ then $S$ is also well-formed.
\end{quote}
\end{proposition}
\begin{proof}
	TODO
\end{proof}

\begin{proposition}[$U$ produces well-formed substitutions] ~
\begin{quote}
	If $U(A_1,A_2)=S$ then $S$ is well-formed.
\end{quote}
\end{proposition}
\begin{proof}
	TODO
\end{proof}

\begin{lemma}
Let $S$, $\{x\mapsto A'\}$, and $\{x\mapsto A\}$ be well-formed substitutions.
	\[ (S \circ \{x\mapsto A'\}) \circ \{x\mapsto A\} =
	S \circ (\{x\mapsto A'\} \circ \{x\mapsto A\}) \]
\end{lemma}
\begin{proof}
TODO
\end{proof}

\begin{lemma} \label{lem:assocsinglesubst}
Let $S_1$, $S_2$, and $\{x\mapsto A\}$ be well-formed substitutions.
\[ (S_1\circ S_2) \circ \{x\mapsto A\} = S_1 \circ (S_2 \circ \{x\mapsto A\}) \]
\end{lemma}
\begin{proof}
By induction on the size of $S_2$.

When $S_2=\emptyset$, trivial.

When $S_2$ is non-empty.

If $x\notin \dom(S_2)$, let $S_2=\{x'\mapsto A'\}\uplus S_2'$.
\begin{align*}
 &~ (S_1\circ S_2) \circ \{x\mapsto A\} \\
=&~ (S_1\circ(\{x'\mapsto A'\}\uplus S_2')) \circ \{x\mapsto A\} \\
=&~ (S_1\circ(S_2'\uplus\{x'\mapsto A'\})) \circ \{x\mapsto A\} \\
=&~ (S_1\circ(S_2'\circ\{x'\mapsto A'\})) \circ \{x\mapsto A\} \\
=&~ ((S_1\circ S_2')\circ\{x'\mapsto A'\}) \circ \{x\mapsto A\}
	& \text{by induction} \\
=&~ (S_1\circ S_2')\circ(\{x'\mapsto A'\} \circ \{x\mapsto A\})
	& \text{by Lemma TODO} \\
=&~ TODO \\
=&~ S_1 \circ (S_2'\circ (\{x'\mapsto A'\} \circ \{x\mapsto A\})) \\
=&~ S_1 \circ ((S_2'\circ \{x'\mapsto A'\}) \circ \{x\mapsto A\}) \\
=&~ S_1 \circ ((S_2'\uplus \{x'\mapsto A'\}) \circ \{x\mapsto A\}) \\
=&~ S_1 \circ ((\{x'\mapsto A'\}\uplus S_2') \circ \{x\mapsto A\}) \\
=&~ S_1 \circ (S_2 \circ \{x\mapsto A\})
\end{align*}


If $x\in \dom(S_2)$, let $S_2=\{x\mapsto A'\}\uplus S_2'$.
\begin{align*}
 &~ (S_1\circ S_2) \circ \{x\mapsto A\} \\
=&~ (S_1\circ(\{x\mapsto A'\}\uplus S_2')) \circ \{x\mapsto A\} \\
=&~ (S_1\circ(S_2'\uplus\{x\mapsto A'\})) \circ \{x\mapsto A\} \\
=&~ (S_1\circ(S_2'\circ\{x\mapsto A'\})) \circ \{x\mapsto A\} \\
=&~ ((S_1\circ S_2')\circ\{x\mapsto A'\}) \circ \{x\mapsto A\}
	& \text{by induction} \\
=&~ (S_1\circ S_2')\circ(\{x\mapsto A'\} \circ \{x\mapsto A\})
	& \text{by Lemma \ref{TODO}} \\
=&~ (S_1\circ S_2')\circ \{x\mapsto A''\} \\
=&~ S_1 \circ (S_2'\circ \{x\mapsto A''\} )
	& \text{by induction} \\
=&~ S_1 \circ (S_2'\circ (\{x\mapsto A'\} \circ \{x\mapsto A\})) \\
=&~ S_1 \circ ((S_2'\circ \{x\mapsto A'\}) \circ \{x\mapsto A\})
	& \text{by Lemma \ref{TODO}} \\
=&~ S_1 \circ ((S_2'\uplus \{x\mapsto A'\}) \circ \{x\mapsto A\}) \\
=&~ S_1 \circ ((\{x\mapsto A'\}\uplus S_2') \circ \{x\mapsto A\}) \\
=&~ S_1 \circ (S_2 \circ \{x\mapsto A\})
\end{align*}


\end{proof}

\begin{theorem}[substitution composition is associative]
	\[(S_1\circ S_2) \circ S_3 = S_1 \circ (S_2 \circ S_3)
	\qquad\text{($S_1, S_2, S_3$ are well-formed)}
	\]
\end{theorem}
\begin{proof}
By induction on the size of $S_3$.

When $S_3=\emptyset$, trivial.

When $S_3$ is non-empty, let $S_3=\{x\mapsto A\}\uplus S_3'$.
\begin{align*}
(S_1\circ S_2) \circ S_3
	&= (S_1\circ S_2) \circ (\{x\mapsto A\}\uplus S_3') \\
	&= (S_1\circ S_2) \circ (\{x\mapsto A\} \circ S_3') \\
	&= ((S_1\circ S_2) \circ \{x\mapsto A\}) \circ S_3'
	& \text{by induction} \\
	&= (S_1\circ(S_2 \circ \{x\mapsto A\})) \circ S_3'
	& \text{by Lemma \ref{lem:assocsinglesubst}} \\
	&= S_1\circ((S_2 \circ \{x\mapsto A\}) \circ S_3')
	& \text{by induction} \\
	&= S_1\circ(S_2 \circ(\{x\mapsto A\} \circ S_3'))
	& \text{by induction} \\
	&= S_1 \circ (S_2 \circ S_3)
\end{align*}
\end{proof}


\begin{lemma}\label{lem:commsinglesinglesubst}
$ \{x\mapsto A\}\circ\{x'\mapsto A'\} = \{x'\mapsto A'\}\circ\{x\mapsto A\} $
\end{lemma}
\begin{proof}
When either $\{x\mapsto A\}$ or $\{x'\mapsto A'\}$ is not well-formed,
\ie, either $x$ occurs in $A$ or $x'$ occurs in $A'$,
both sides of the equation above fail. The failure will rise from
the occurs check on a single substitution on types (Figure \ref{fig:algU}).
It is easy to check this proceeding by the second equation of $\circ$
for each side. We leave this as an exercise to the reader.

When $x$ occurs in $A'$ and $x'$ occurs $A$ at the same time,
both sides of the equation above fail as well. The failure will rise from
the occurs check on a single substitution on types (Figure \ref{fig:algU}).
It is easy to check this proceeding by the second equation of $\circ$.
We leave this as an exercise to the reader.

When neither $x$ nor $x'$ occur in $A$ and $A'$, it is easy to see
that this lemma holds, by using the second equation of $\circ$.
\begin{align*}
\{x\mapsto A\}\circ\{x'\mapsto A'\}
&= \{x\mapsto A[\{x\mapsto A\} A'/x']\}\uplus\{x'\mapsto\{x\mapsto A\} A'\} \\
&= \{x\mapsto A\}\uplus\{x'\mapsto A'\} \\
&= \{x\mapsto A'\}\uplus\{x\mapsto A\} \\
&= \{x'\mapsto A'[\{x'\mapsto A'\}A/x]\}\uplus\{x\mapsto\{x'\mapsto A'\}A\} \\
&= \{x'\mapsto A'\}\circ\{x\mapsto A\}
\end{align*}

The other two cases to consider are:
\begin{itemize}
\item[(1)] $x$ occurs in $A'$ but $x'$ does not occur in $A$
\begin{align*}
\{x\mapsto A\}\circ\{x'\mapsto A'\}
&= \{x\mapsto A[\{x\mapsto A\} A'/x']\}\uplus\{x'\mapsto\{x\mapsto A\} A'\} \\
&= \{x\mapsto A\}\uplus\{x'\mapsto A'[A/x]\} \\
&= \{x'\mapsto A'[A/x]\}\uplus\{x\mapsto A\} \\
&= \{x'\mapsto A'[\{x'\mapsto A'\}A/x]\}\uplus\{x\mapsto\{x'\mapsto A'\}A\} \\
&= \{x'\mapsto A'\}\circ\{x\mapsto A\}
\end{align*}
\item[(2)] $x'$ occurs in $A$ but $x$ does not occur in $A'$
\begin{align*}
\{x\mapsto A\}\circ\{x'\mapsto A'\}
&= \{x\mapsto A[\{x\mapsto A\} A'/x']\}\uplus\{x'\mapsto\{x\mapsto A\} A'\} \\
&= \{x\mapsto A[A'/x']\}\uplus\{x'\mapsto A'\} \\
&= \{x'\mapsto A'\}\uplus\{x\mapsto A[A'/x']\} \\
&= \{x'\mapsto A'[\{x'\mapsto A'\}A/x]\}\uplus\{x\mapsto\{x'\mapsto A'\}A\} \\
&= \{x'\mapsto A'\}\circ\{x\mapsto A\}
\end{align*}
\end{itemize}
\end{proof}

\begin{lemma}\label{lem:commsingletonsubst}
	$S \circ \{x\mapsto A\} = \{x\mapsto A\} \circ S
	\quad (x \notin \dom(S))$
\end{lemma}
\begin{proof} By induction on the size of $S$.

When $S=\emptyset$ it holds trivially.

When $S$ is non-empty, that is, let $S=\{x'\mapsto A'\}\uplus S'$,
\begin{align*}
S\circ\{x\mapsto A\}
&= (\{x'\mapsto A'\}\uplus S') \circ \{x\mapsto A\} \\
&= (\{x'\mapsto A'\}\circ S') \circ \{x\mapsto A\} \\
&= \{x'\mapsto A'\} \circ (S' \circ \{x\mapsto A\})
& \text{by associativity of $\circ$} \\
&= \{x'\mapsto A'\} \circ (\{x\mapsto A\} \circ S')
& \text{by induction} \\
&= (\{x'\mapsto A'\} \circ \{x\mapsto A\}) \circ S'
& \text{by associativity of $\circ$} \\
&= (\{x\mapsto A\} \circ \{x'\mapsto A\}') \circ S'
& \text{by Lemma \ref{lem:commsinglesinglesubst}} \\
&= \{x\mapsto A\} \circ (\{x'\mapsto A\}' \circ S')
& \text{by associativity of $\circ$} \\
&= \{x\mapsto A\} \circ S
\end{align*}
\end{proof}

\begin{theorem}[substitution composition is commutative]
\[ S_1\circ S_2 = S_2\circ S_1 \qquad\text{($S_1$ and $S_2$ are well-formed)} \]
\end{theorem}
\begin{proof}
By induction on the size of $S_2$.

When $S_2=\emptyset$ it holds trivially.

When $S_2$ is non-empty, let $S_2=\{x\mapsto A_2\}\uplus S_2'$,
\begin{align*}
S_1 \circ S_2
	&= S_1 \circ (\{x\mapsto A_2\}\uplus S_2') \\
	&= S_1 \circ (\{x\mapsto A_2\}\circ S_2') \\
	&= (S_1 \circ \{x\mapsto A_2\}) \circ S_2'
	& \text{by associativity of $\circ$} \\
	&= (\{x\mapsto A_2\}\circ S_1) \circ S_2'
	& \text{by Lemma \ref{lem:commsingletonsubst}} \\
	&= \{x\mapsto A_2\}\circ (S_1 \circ S_2')
	& \text{by associativity of $\circ$} \\
	&= \{x\mapsto A_2\}\circ (S_2' \circ S_1)
	& \text{by induction} \\
	&= (\{x\mapsto A_2\}\circ S_2') \circ S_1
	& \text{by associativity of $\circ$} \\
	&= (\{x\mapsto A_2\}\uplus S_2') \circ S_1 \\
	&= S_2 \circ S_1
\end{align*}
\end{proof}

\begin{lemma} $(S \circ S') A = (S \circ S')(S' A)$
	\label{lem:dupsubstR}
\end{lemma}
\begin{proof}
	TODO
\end{proof}

\begin{lemma} $(S \circ S') A = (S \circ S')(S A)$
	\label{lem:dupsubstL}
\end{lemma}
\begin{proof}
	TODO
\end{proof}


\begin{theorem}[$U$ is sound] \label{prop:soundU}
$ \inference{U(A_1,A_2)=S}{S A_1 = S A_2} $
\end{theorem}
\begin{proof}
By induction on the structure of $A_1$ and $A_2$.
%% By induction on the computation of $U$.
%% Since we assume $U(A_1,A_2)=S$, that is, $U$ succeeds and returns $S$,
%% we know that the computation of $U(A_1,A_2)$ is finite.
%% Therefore, we can induct on the computation of $U$.

The base cases (\ie, $U(\iota,\iota)$, $U(x,x)$, $U(x_1,x_2)$,
			$U(x_1,A_2)$, $U(A_1,x_2)$) are trivial.

In the inductive case $U(A_1 -> B_1, A_2 -> B_2)$, we know that
\[ \inference{U(A_1,A_2)=S' }{S'  A_1 = S'  A_2} ~\text{and}~
   \inference{U(B_1,B_2)=S''}{S'' B_1 = S'' B_2} ~\text{by induction.}
\]
Then, $U(A_1 -> B_1, A_2 -> B_2)=S'\circ S''$ by definition.
\begin{align*}
 &~(S'\circ S'')(A_1 -> B_1) \\
=&~ (S'\circ S'') A_1 -> (S'\circ S'') B_1 \\
=&~ (S'\circ S'')(S' A_1) -> (S'\circ S'')(S'' B_1)
 & \text{by Lemma \ref{lem:dupsubstR} and Lemma \ref{lem:dupsubstL}} \\
=&~ (S'\circ S'')(S' A_2) -> (S'\circ S'')(S'' B_2)
 & \text{by what we know from induction} \\
=&~ (S'\circ S'') A_2 -> (S'\circ S'') B_2
 & \text{by Lemma \ref{lem:dupsubstR} and Lemma \ref{lem:dupsubstL}} \\
=&~ (S'\circ S'')(A_2 -> B_2)
\end{align*}
Therefore, $U(A_1 -> B_1, A_2 -> B_2)=S'\circ S''$ is a unifier.
\end{proof}

\begin{theorem}[$U$ is complete] \label{prop:completeU}
$ \inference{S A_1 = S A_2}{\exists S'.\, U(A_1,A_2)\circ S' = S} $
\end{theorem}
\begin{proof}
	TODO
\end{proof}


